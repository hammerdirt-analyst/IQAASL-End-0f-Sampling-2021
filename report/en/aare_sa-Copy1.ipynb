{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# home brew utitilties\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchart_kwargs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mck\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msr_ut\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msut\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# images and display\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resources'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# This is a report using the data from IQAASL.\n",
    "# IQAASL was a project funded by the Swiss Confederation\n",
    "# It produces a summary of litter survey results for a defined region.\n",
    "# These charts serve as the models for the development of plagespropres.ch\n",
    "# The data is gathered by volunteers.\n",
    "# Please remember all copyrights apply, please give credit when applicable\n",
    "# The repo is maintained by the community effective January 01, 2022\n",
    "# There is ample opportunity to contribute, learn and teach\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# Dies ist ein Bericht, der die Daten von IQAASL verwendet.\n",
    "# IQAASL war ein von der Schweizerischen Eidgenossenschaft finanziertes Projekt.\n",
    "# Es erstellt eine Zusammenfassung der Ergebnisse der Littering-Umfrage für eine bestimmte Region.\n",
    "# Diese Grafiken dienten als Vorlage für die Entwicklung von plagespropres.ch.\n",
    "# Die Daten werden von Freiwilligen gesammelt.\n",
    "# Bitte denken Sie daran, dass alle Copyrights gelten, bitte geben Sie den Namen an, wenn zutreffend.\n",
    "# Das Repo wird ab dem 01. Januar 2022 von der Community gepflegt.\n",
    "# Es gibt reichlich Gelegenheit, etwas beizutragen, zu lernen und zu lehren.\n",
    "# Kontakt dev@hammerdirt.ch\n",
    "\n",
    "# Il s'agit d'un rapport utilisant les données de IQAASL.\n",
    "# IQAASL était un projet financé par la Confédération suisse.\n",
    "# Il produit un résumé des résultats de l'enquête sur les déchets sauvages pour une région définie.\n",
    "# Ces tableaux ont servi de modèles pour le développement de plagespropres.ch\n",
    "# Les données sont recueillies par des bénévoles.\n",
    "# N'oubliez pas que tous les droits d'auteur s'appliquent, veuillez indiquer le crédit lorsque cela est possible.\n",
    "# Le dépôt est maintenu par la communauté à partir du 1er janvier 2022.\n",
    "# Il y a de nombreuses possibilités de contribuer, d'apprendre et d'enseigner.\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# sys, file and nav packages:\n",
    "import datetime as dt\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# charting:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "# home brew utitilties\n",
    "import resources.chart_kwargs as ck\n",
    "import resources.sr_ut as sut\n",
    "\n",
    "# images and display\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "# set some parameters:\n",
    "start_date = \"2020-03-01\"\n",
    "end_date =\"2021-05-31\"\n",
    "start_end = [start_date, end_date]\n",
    "a_fail_rate = 50\n",
    "unit_label = \"p/100m\"\n",
    "\n",
    "a_color = \"saddlebrown\"\n",
    "\n",
    "# colors for gradients\n",
    "cmap2 = ck.cmap2\n",
    "colors_palette = ck.colors_palette\n",
    "\n",
    "# set the maps\n",
    "bassin_map = \"resources/maps/survey_areas/aare_scaled.jpeg\"\n",
    "\n",
    "# top level aggregation\n",
    "top = \"All survey areas\"\n",
    "\n",
    "# define the feature level and components\n",
    "this_feature = {'slug':'aare', 'name':\"Aare survey area\", 'level':'river_bassin'}\n",
    "this_level = 'water_name_slug'\n",
    "this_bassin = \"aare\"\n",
    "bassin_label = \"Aare survey area\"\n",
    "\n",
    "lakes_of_interest = ['bielersee', 'neuenburgersee', 'brienzersee', 'thunersee',]\n",
    "# explanatory variables:\n",
    "luse_exp = [\"% buildings\", \"% recreation\", \"% agg\", \"% woods\", \"streets km\", \"intersects\"]\n",
    "\n",
    "# common aggregations\n",
    "agg_pcs_quantity = {unit_label:\"sum\", \"quantity\":\"sum\"}\n",
    "agg_pcs_median = {unit_label:\"median\", \"quantity\":\"sum\"}\n",
    "\n",
    "# aggregation of dimensional data\n",
    "agg_dims = {\"total_w\":\"sum\", \"mac_plast_w\":\"sum\", \"area\":\"sum\", \"length\":\"sum\"}\n",
    "\n",
    "# columns needed\n",
    "use_these_cols = [\"loc_date\" ,\n",
    "                  \"% to buildings\",\n",
    "                  \"% to trans\", \n",
    "                  \"% to recreation\",\n",
    "                  \"% to agg\",\n",
    "                  \"% to woods\",\n",
    "                  \"population\",\n",
    "                  this_level,\n",
    "                  \"streets km\",\n",
    "                  \"intersects\",\n",
    "                  \"length\",\n",
    "                  \"groupname\",\n",
    "                  \"code\"\n",
    "                 ]\n",
    "\n",
    "# get your data:\n",
    "dfBeaches = pd.read_csv(\"resources/beaches_with_land_use_rates.csv\")\n",
    "dfCodes = pd.read_csv(\"resources/codes_with_group_names_2015.csv\")\n",
    "dfDims = pd.read_csv(\"resources/corrected_dims.csv\")\n",
    "\n",
    "# set the index of the beach data to location slug\n",
    "dfBeaches.set_index(\"slug\", inplace=True)\n",
    "\n",
    "# map water_name_slug to water_name\n",
    "wname_wname = dfBeaches[[\"water_name_slug\",\"water_name\"]].reset_index(drop=True).drop_duplicates().set_index(\"water_name_slug\")\n",
    "\n",
    "dfCodes.set_index(\"code\", inplace=True)\n",
    "\n",
    "codes_to_change = [\n",
    "    [\"G74\", \"description\", \"Insulation foams\"],\n",
    "    [\"G940\", \"description\", \"Foamed EVA for crafts and sports\"],\n",
    "    [\"G96\", \"description\", \"Sanitary-pads/tampons, applicators\"],\n",
    "    [\"G178\", \"description\", \"Metal bottle caps and lids\"],\n",
    "    [\"G82\", \"description\", \"Expanded foams 2.5cm - 50cm\"],\n",
    "    [\"G81\", \"description\", \"Expanded foams .5cm - 2.5cm\"],\n",
    "    [\"G117\", \"description\", \"Expanded foams < 5mm\"],\n",
    "    [\"G75\", \"description\", \"Plastic/foamed polystyrene 0 - 2.5cm\"],\n",
    "    [\"G76\", \"description\", \"Plastic/foamed polystyrene 2.5cm - 50cm\"],\n",
    "    [\"G24\", \"description\", \"Plastic lid rings\"],\n",
    "    [\"G33\", \"description\", \"Lids for togo drinks plastic\"],\n",
    "    [\"G3\", \"description\", \"Plastic bags, carier bags\"],\n",
    "    [\"G204\", \"description\", \"Bricks, pipes not plastic\"],\n",
    "    [\"G904\", \"description\", \"Plastic fireworks\"],\n",
    "    [\"G211\", \"description\", \"Swabs, bandaging, medical\"],\n",
    "]\n",
    "\n",
    "for x in codes_to_change:\n",
    "    dfCodes = sut.shorten_the_value(x, dfCodes)\n",
    "\n",
    "# the surveyor designated the object as aluminum instead of metal\n",
    "dfCodes.loc[\"G708\", \"material\"] = \"Metal\"\n",
    "\n",
    "# make a map to the code descriptions\n",
    "code_description_map = dfCodes.description\n",
    "\n",
    "# make a map to the code materials\n",
    "code_material_map = dfCodes.material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(aaresa)=\n",
    "# Aare\n",
    "\n",
    "<a href=\"aare_sa_de.html\"> Deutsch </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Unten:__ Karte des Erhebungsgebiets März 2020 bis Mai 2021. Der Durchmesser der Punktsymbole entspricht dem Median der Abfallobjekte pro 100 Meter (p/100 m) am jeweiligen Erhebungsort.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "sut.display_image_ipython(bassin_map, thumb=(800,450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Erhebungsorte und Landnutzungsprofile¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# this is the data before the expanded foams and fragmented plastics are aggregated to Gfrags and Gfoams\n",
    "before_agg = pd.read_csv(\"resources/checked_before_agg_sdata_eos_2020_21.csv\")\n",
    "\n",
    "# this is the aggregated survey data that is being used\n",
    "# a_data is all the data in the survey period\n",
    "a_data = pd.read_csv(F\"resources/checked_sdata_eos_2020_21.csv\")\n",
    "a_data[\"date\"] = pd.to_datetime(a_data.date)\n",
    "\n",
    "a_data.rename(columns={\"% to agg\":\"% ag\", \"% to recreation\": \"% recreation\", \"% to woods\":\"% woods\", \"% to buildings\":\"% buildings\"}, inplace=True)\n",
    "luse_exp = [\"% buildings\", \"% recreation\", \"% ag\", \"% woods\", \"streets km\", \"intersects\"]\n",
    "\n",
    "fd = sut.feature_data(a_data, this_feature[\"level\"], these_features=[this_feature[\"slug\"]])\n",
    "\n",
    "# cumulative statistics for each code\n",
    "code_totals = sut.the_aggregated_object_values(fd, agg=agg_pcs_median, description_map=code_description_map, material_map=code_material_map)    \n",
    "\n",
    "# daily survey totals\n",
    "dt_all = fd.groupby([\"loc_date\",\"location\",this_level, \"city\",\"date\"], as_index=False).agg(agg_pcs_quantity )\n",
    "\n",
    "# the materials table\n",
    "fd_mat_totals = sut.the_ratio_object_to_total(code_totals)\n",
    "\n",
    "# summary statistics, nsamples, nmunicipalities, names of citys, population\n",
    "t = sut.make_table_values(fd, col_nunique=[\"location\", \"loc_date\", \"city\"], col_sum=[\"quantity\"], col_median=[])\n",
    "\n",
    "# make a map to the population values for each survey location/city\n",
    "fd_pop_map = dfBeaches.loc[fd.location.unique()][[\"city\", \"population\"]].copy()\n",
    "fd_pop_map.drop_duplicates(inplace=True)\n",
    "\n",
    "# update t with the population data\n",
    "t.update(sut.make_table_values(fd_pop_map, col_nunique=[\"city\"], col_sum=[\"population\"], col_median=[]))\n",
    "\n",
    "# update t with the list of locations from fd\n",
    "t.update({\"locations\":fd.location.unique()})\n",
    "\n",
    "# the lake and river names in the survey area\n",
    "lakes = dfBeaches.loc[(dfBeaches.index.isin(t[\"locations\"]))&(dfBeaches.water == \"l\")][\"water_name\"].unique()\n",
    "rivers = dfBeaches.loc[(dfBeaches.index.isin(t[\"locations\"]))&(dfBeaches.water == \"r\")][\"water_name\"].unique()\n",
    "\n",
    "# join the strings into comma separated list\n",
    "obj_string = \"{:,}\".format(t[\"quantity\"])\n",
    "surv_string = \"{:,}\".format(t[\"loc_date\"])\n",
    "pop_string = \"{:,}\".format(int(t[\"population\"]))\n",
    "\n",
    "# make strings\n",
    "date_quantity_context = F\"Im Zeitraum von {start_date[:-3]}  bis {end_date[:-3]} wurden im Rahmen von {surv_string} Datenerhebungen insgesamt {obj_string } Objekte entfernt und identifiziert.\"\n",
    "\n",
    "geo_context = F\"Die Ergebnisse des {bassin_label} umfassen {t['location']} Orte, {t['city']} Gemeinden und eine Gesamtbevölkerung von etwa {pop_string} Einwohnenden..\"\n",
    "# admin_context = F\"There are {t['city']} different municipalities represented in these results with a combined population of approximately {pop_string}.\"\n",
    "munis_joined = \", \".join(sorted(fd_pop_map[\"city\"]))\n",
    "lakes_joined = \", \".join(sorted(lakes))\n",
    "rivers_joined = \", \".join(sorted(rivers))\n",
    "\n",
    "# put that all together:\n",
    "lake_string = F\"\"\"\n",
    "{date_quantity_context} {geo_context }\n",
    "\n",
    "*{bassin_label} lakes:*\\n\\n>{lakes_joined}\n",
    "\n",
    "*{bassin_label} rivers:*\\n\\n>{rivers_joined}\n",
    "\n",
    "*{bassin_label} municipalities:*\\n\\n>{munis_joined}\n",
    "\"\"\"\n",
    "md(lake_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land use profile of the surveys\n",
    "\n",
    "The land use is reported as the percent of total area attributed to each land use category within a 1500m radius of the survey location.  \n",
    "\n",
    "Streets are reported as the total number of kilometers of streets within the 1500m radius. Intersects is also an ordinal ranking of the number of rivers/canals that intersect a lake within 1500m of the survey location. \n",
    "\n",
    "The ratio of the number of samples under varying land use profiles gives an indication of the environmental and economic conditions of the survey sites.\n",
    "\n",
    "For more information [*Land use profile*](luseprofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Below:__ Distribution of land use characteristics.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "# the ratio of samples with respect to the different land use characteristics for each survey area\n",
    "# the data to use is the unique combinations of loc_date and the land_use charcteristics of each location\n",
    "project_profile = a_data[[\"loc_date\", this_feature[\"level\"], *luse_exp]].drop_duplicates()\n",
    "dt_nw = fd[[\"loc_date\", this_feature[\"level\"], *luse_exp]].drop_duplicates()\n",
    "\n",
    "# labels and levels\n",
    "comps = [this_feature[\"slug\"]]\n",
    "comp_labels = {x:wname_wname.loc[x][0] for x in fd[this_level].unique()}\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9,8), sharey=\"row\")\n",
    "\n",
    "for i, n in enumerate(luse_exp):\n",
    "    r = i%2\n",
    "    c = i%3\n",
    "    ax=axs[r,c]\n",
    "    for element in[this_feature[\"slug\"]]:\n",
    "        data=dt_nw[dt_nw[this_feature[\"level\"]] == element][n].values\n",
    "        the_data = ECDF(data)\n",
    "        \n",
    "        # plot that\n",
    "        sns.lineplot(x=the_data.x, y=the_data.y, ax=ax, label=bassin_label)\n",
    "    \n",
    "    # get the dist for all here\n",
    "    a_all_surveys =  ECDF(project_profile[n].values)\n",
    "    \n",
    "    # plot that    \n",
    "    sns.lineplot(x=a_all_surveys.x, y=a_all_surveys.y, ax=ax, label=\"All survey areas\", color=\"magenta\")\n",
    "    \n",
    "    # get the median from the data\n",
    "    the_median = np.median(data)\n",
    "    \n",
    "    # plot the median and drop horzontal and vertical lines\n",
    "    ax.scatter([the_median], 0.5, color=\"red\",s=50, linewidth=2, zorder=100, label=\"the median\")\n",
    "    ax.vlines(x=the_median, ymin=0, ymax=0.5, color=\"red\", linewidth=2)\n",
    "    ax.hlines(xmax=the_median, xmin=0, y=0.5, color=\"red\", linewidth=2)\n",
    "    \n",
    "    if i <= 3:\n",
    "        if c == 0:            \n",
    "            ax.set_ylabel(\"Ratio of samples\", **ck.xlab_k)\n",
    "        ax.xaxis.set_major_formatter(ticker.PercentFormatter(1.0, 0, \"%\"))        \n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()    \n",
    "    ax.set_xlabel(n, **ck.xlab_k)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9, hspace=.3)\n",
    "plt.suptitle(\"Land use within 1500m of the survey location\", ha=\"center\", y=1, fontsize=16)\n",
    "fig.legend(handles, labels, bbox_to_anchor=(.5,.94), loc=\"center\", ncol=3)    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative totals by water feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# aggregate the dimensional data\n",
    "dims_parameters = dict(this_level=this_level, \n",
    "                       locations=fd.location.unique(), \n",
    "                       start_end=start_end, \n",
    "                       agg_dims=agg_dims)\n",
    "\n",
    "dims_table = sut.gather_dimensional_data(dfDims, **dims_parameters)\n",
    "\n",
    "# map the qauntity to the dimensional data\n",
    "q_map = fd.groupby(this_level).quantity.sum()\n",
    "\n",
    "# collect the number of samples from the survey total data:\n",
    "for name in dims_table.index:\n",
    "    dims_table.loc[name, \"samples\"] = fd[fd[this_level] == name].loc_date.nunique()\n",
    "    dims_table.loc[name, \"quantity\"] = q_map[name]\n",
    "\n",
    "# add proper names for display\n",
    "dims_table[\"water_feature\"] = dims_table.index.map(lambda x: comp_labels[x])\n",
    "dims_table.set_index(\"water_feature\", inplace=True)\n",
    "   \n",
    "# get the sum of all survey areas\n",
    "dims_table.loc[this_feature[\"name\"]]= dims_table.sum(numeric_only=True, axis=0)\n",
    "\n",
    "# for display\n",
    "dims_table.sort_values(by=[\"quantity\"], ascending=False, inplace=True)\n",
    "dims_table.rename(columns={\"samples\":\"samples\",\"quantity\":\"items\", \"total_w\":\"total kg\", \"mac_plast_w\":\"plastic kg\", \"area\":\"m²\", \"length\":\"meters\"}, inplace=True)\n",
    "\n",
    "# format kilos and text strings\n",
    "dims_table[\"plastic kg\"] = dims_table[\"plastic kg\"]/1000\n",
    "dims_table[[\"m²\", \"meters\", \"samples\", \"items\"]] = dims_table[[\"m²\", \"meters\", \"samples\", \"items\"]].applymap(lambda x: \"{:,}\".format(int(x)))\n",
    "dims_table[[\"plastic kg\", \"total kg\"]] = dims_table[[\"plastic kg\", \"total kg\"]].applymap(lambda x: \"{:.2f}\".format(x))\n",
    "\n",
    "# figure caption\n",
    "agg_caption = F\"\"\"\n",
    "*__Below:__ The cumulative weights and measures for the {this_feature[\"name\"]} and water bodies.*\n",
    "\"\"\"\n",
    "md(agg_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# make table\n",
    "data = dims_table.reset_index()\n",
    "colLabels = data.columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(colLabels)*1.8,len(data)*.7))\n",
    "sut.hide_spines_ticks_grids(ax)\n",
    "\n",
    "table_one = sut.make_a_table(ax, data.values, colLabels=colLabels, colWidths=[.28, *[.12]*6], a_color=a_color)\n",
    "table_one.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of survey results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the surveys to chart\n",
    "fd_dindex = dt_all.set_index(\"date\")\n",
    "\n",
    "# all the other surveys\n",
    "ots = dict(level_to_exclude=this_feature[\"level\"], components_to_exclude=fd[this_feature[\"level\"]].unique())\n",
    "dts_date = sut.the_other_surveys(a_data, **ots)\n",
    "dts_date.head()\n",
    "\n",
    "# the survey totals from all other survey areas\n",
    "dts_date = dts_date.groupby([\"loc_date\",\"date\"], as_index=False)[unit_label].sum()\n",
    "dts_date.set_index(\"date\", inplace=True)\n",
    "\n",
    "# get the monthly or quarterly results for the feature\n",
    "resample_plot, rate = sut.quarterly_or_monthly_values(fd_dindex , this_feature[\"name\"], vals=unit_label, quarterly=[\"ticino\"])\n",
    "\n",
    "# scale the chart as needed to accomodate for extreme values\n",
    "y_lim = 95\n",
    "y_limit = np.percentile(dts_date[unit_label], y_lim)\n",
    "\n",
    "# label for the chart that alerts to the scale\n",
    "not_included = F\"Values greater than {round(y_limit, 1)} not shown.\"\n",
    "\n",
    "# figure caption\n",
    "chart_notes = F\"\"\"\n",
    "*__Left:__ {this_feature[\"name\"]}, {start_date[:7]} through {end_date[:7]}, n={t[\"loc_date\"]}. {not_included} __Right:__ {this_feature[\"name\"]} empirical cumulative distribution of survey results.*\n",
    "\"\"\"\n",
    "md(chart_notes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# months locator, can be confusing\n",
    "# https://matplotlib.org/stable/api/dates_api.html\n",
    "months = mdates.MonthLocator(interval=1)\n",
    "months_fmt = mdates.DateFormatter(\"%b\")\n",
    "days = mdates.DayLocator(interval=7)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "# the survey totals by day\n",
    "ax = axs[0]\n",
    "\n",
    "# feature surveys\n",
    "sns.scatterplot(data=dts_date, x=dts_date.index, y=unit_label, label=top, color=\"black\", alpha=0.4,  ax=ax)\n",
    "# all other surveys\n",
    "sns.scatterplot(data=fd_dindex, x=fd_dindex.index, y=unit_label, label=this_feature[\"name\"], color=\"red\", s=34, ec=\"white\", ax=ax)\n",
    "\n",
    "# monthly or quaterly plot\n",
    "sns.lineplot(data=resample_plot, x=resample_plot.index, y=resample_plot, label=F\"{this_feature['name']}: {rate} median\", color=\"magenta\", ax=ax)\n",
    "\n",
    "ax.set_ylim(0,y_limit )\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.xaxis.set_minor_locator(days)\n",
    "ax.xaxis.set_major_formatter(months_fmt)\n",
    "ax.legend()\n",
    "\n",
    "# the cumlative distributions:\n",
    "axtwo = axs[1]\n",
    "\n",
    "# the feature of interest\n",
    "feature_ecd = ECDF(dt_all[unit_label].values)    \n",
    "sns.lineplot(x=feature_ecd.x, y=feature_ecd.y, color=\"darkblue\", ax=axtwo, label=this_feature[\"name\"])\n",
    "\n",
    "# the other features\n",
    "other_features = ECDF(dts_date[unit_label].values)\n",
    "sns.lineplot(x=other_features.x, y=other_features.y, color=\"magenta\", label=top, linewidth=1, ax=axtwo)\n",
    "\n",
    "axtwo.set_xlabel(unit_label, **ck.xlab_k14)\n",
    "axtwo.set_ylabel(\"Ratio of samples\", **ck.xlab_k14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary data and material types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# figure caption\n",
    "summary_of_survey_totals = F\"\"\"\n",
    "*__Left:__ {this_feature[\"name\"]} summary of survey totals. __Right:__ {this_feature[\"name\"]} material type and percent of total.*\n",
    "\"\"\"\n",
    "md(summary_of_survey_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# get the basic statistics from pd.describe\n",
    "cs = dt_all[unit_label].describe().round(2)\n",
    "\n",
    "# change the names\n",
    "csx = sut.change_series_index_labels(cs, sut.create_summary_table_index(unit_label, lang=\"EN\"))\n",
    "\n",
    "combined_summary = sut.fmt_combined_summary(csx, nf=[])\n",
    "\n",
    "fd_mat_totals = sut.fmt_pct_of_total(fd_mat_totals)\n",
    "fd_mat_totals = sut.make_string_format(fd_mat_totals)\n",
    "\n",
    "# applly new column names for printing\n",
    "cols_to_use = {\"material\":\"Material\",\"quantity\":\"Quantity\", \"% of total\":\"% of total\"}\n",
    "fd_mat_t = fd_mat_totals[cols_to_use.keys()].values\n",
    "\n",
    "# make tables\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# summary table\n",
    "# names for the table columns\n",
    "a_col = [this_feature[\"name\"], \"total\"]\n",
    "\n",
    "axone = axs[0]\n",
    "sut.hide_spines_ticks_grids(axone)\n",
    "\n",
    "table_two = sut.make_a_table(axone, combined_summary,  colLabels=a_col, colWidths=[.5,.25,.25],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_two.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_two.set_fontsize(14)\n",
    "\n",
    "# material table\n",
    "axtwo = axs[1]\n",
    "axtwo.set_xlabel(\" \")\n",
    "sut.hide_spines_ticks_grids(axtwo)\n",
    "\n",
    "table_three = sut.make_a_table(axtwo, fd_mat_t,  colLabels=list(cols_to_use.values()), colWidths=[.4, .3,.3],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_three.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most common objects\n",
    "\n",
    "The most common objects are the **ten most abundant by quantity AND/OR objects identified in at least 50% of all surveys.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the top ten by quantity\n",
    "most_abundant = code_totals.sort_values(by=\"quantity\", ascending=False)[:10]\n",
    "\n",
    "# the most common\n",
    "most_common = code_totals[code_totals[\"fail rate\"] >= a_fail_rate].sort_values(by=\"quantity\", ascending=False)\n",
    "\n",
    "# merge with most_common and drop duplicates\n",
    "m_common = pd.concat([most_abundant, most_common]).drop_duplicates()\n",
    "\n",
    "# get percent of total\n",
    "m_common_percent_of_total = m_common.quantity.sum()/code_totals.quantity.sum()\n",
    "\n",
    "# figure caption\n",
    "rb_string = F\"\"\"\n",
    "*__Below:__ {this_feature['name']} most common objects: fail rate >/= {a_fail_rate}%  and/or top ten by quantity. Combined, the most abundant objects represent {int(m_common_percent_of_total*100)}% of all objects found.*\n",
    "\n",
    "Note : {unit_label} = median survey value.\n",
    "\"\"\"\n",
    "md(rb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# format values for table\n",
    "m_common[\"item\"] = m_common.index.map(lambda x: code_description_map.loc[x])\n",
    "m_common[\"% of total\"] = m_common[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "m_common[\"quantity\"] = m_common.quantity.map(lambda x: \"{:,}\".format(x))\n",
    "m_common[\"fail rate\"] = m_common[\"fail rate\"].map(lambda x: F\"{x}%\")\n",
    "m_common[unit_label] = m_common[unit_label].map(lambda x: F\"{round(x,1)}\")\n",
    "\n",
    "cols_to_use = {\"item\":\"Item\",\"quantity\":\"Quantity\", \"% of total\":\"% of total\", \"fail rate\":\"Fail rate\", unit_label:unit_label}\n",
    "all_survey_areas = m_common[cols_to_use.keys()].values\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10,len(m_common)*.7))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_four = sut.make_a_table(axs, all_survey_areas,  colLabels=list(cols_to_use.values()), colWidths=[.52, .12,.12,.12, .12],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_four.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_four.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common objects by water feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "rb_string = F\"\"\"\n",
    "*__Below:__ {this_feature[\"name\"]} most common objects: median {unit_label}*\n",
    "\"\"\"\n",
    "md(rb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# aggregated survey totals for the most common codes for all the water features\n",
    "m_common_st = fd[fd.code.isin(m_common.index)].groupby([this_level, \"loc_date\",\"code\"], as_index=False).agg(agg_pcs_quantity)\n",
    "m_common_ft = m_common_st.groupby([this_level, \"code\"], as_index=False)[unit_label].median()\n",
    "\n",
    "# proper name of water feature for display\n",
    "m_common_ft[\"f_name\"] = m_common_ft[this_level].map(lambda x: comp_labels[x])\n",
    "\n",
    "# map the desctiption to the code\n",
    "m_common_ft[\"item\"] = m_common_ft.code.map(lambda x: code_description_map.loc[x])\n",
    "\n",
    "# pivot that\n",
    "m_c_p = m_common_ft[[\"item\", unit_label, \"f_name\"]].pivot(columns=\"f_name\", index=\"item\")\n",
    "\n",
    "# quash the hierarchal column index\n",
    "m_c_p.columns = m_c_p.columns.get_level_values(1)\n",
    "\n",
    "# the aggregated totals for the survey area\n",
    "\n",
    "c = sut.aggregate_to_group_name(fd[fd.code.isin(m_common.index)], column=\"code\", name=this_feature[\"name\"], val=\"med\")\n",
    "\n",
    "m_c_p[this_feature[\"name\"]]= sut.change_series_index_labels(c, {x:code_description_map.loc[x] for x in c.index})\n",
    "\n",
    "# the aggregated totals of all the data\n",
    "c = sut.aggregate_to_group_name(a_data[(a_data.code.isin(m_common.index))], column=\"code\", name=top, val=\"med\")\n",
    "m_c_p[top] = sut.change_series_index_labels(c, {x:code_description_map.loc[x] for x in c.index})\n",
    "\n",
    "# chart that\n",
    "fig, ax  = plt.subplots(figsize=(len(m_c_p.columns)*.9,len(m_c_p)*.9))\n",
    "axone = ax\n",
    "\n",
    "sns.heatmap(m_c_p, ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, fmt=\".1f\", square=True, cbar=False, linewidth=.1, linecolor=\"white\")\n",
    "axone.set_xlabel(\"\")\n",
    "axone.set_ylabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"x\")\n",
    "axone.tick_params(labelsize=12, which=\"both\", axis=\"y\")\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common objects monthly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# collect the survey results of the most common objects\n",
    "m_common_m = fd[(fd.code.isin(m_common.index))].groupby([\"loc_date\",\"date\",\"code\", \"groupname\"], as_index=False).agg(agg_pcs_quantity)\n",
    "m_common_m.set_index(\"date\", inplace=True)\n",
    "\n",
    "# set the order of the chart, group the codes by groupname columns\n",
    "an_order = m_common_m.groupby([\"code\",\"groupname\"], as_index=False).quantity.sum().sort_values(by=\"groupname\")[\"code\"].values\n",
    "\n",
    "# a manager dict for the monthly results of each code\n",
    "mgr = {}\n",
    "\n",
    "# get the monhtly results for each code:\n",
    "for a_group in an_order:\n",
    "    # resample by month\n",
    "    a_plot = m_common_m[(m_common_m.code==a_group)][unit_label].resample(\"M\").mean().fillna(0)\n",
    "    this_group = {a_group:a_plot}\n",
    "    mgr.update(this_group)\n",
    "\n",
    "monthly_mc = F\"\"\"\n",
    "*__Below:__ {this_feature[\"name\"]}, monthly average survey result {unit_label}, with detail of the most common objects.*\n",
    "\"\"\"\n",
    "md(monthly_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "months={\n",
    "    0:\"Jan\",\n",
    "    1:\"Feb\",\n",
    "    2:\"Mar\",\n",
    "    3:\"Apr\",\n",
    "    4:\"May\",\n",
    "    5:\"Jun\",\n",
    "    6:\"Jul\",\n",
    "    7:\"Aug\",\n",
    "    8:\"Sep\",\n",
    "    9:\"Oct\",\n",
    "    10:\"Nov\",\n",
    "    11:\"Dec\"\n",
    "}\n",
    "\n",
    "# convenience function to lable x axis\n",
    "def new_month(x):\n",
    "    if x <= 11:\n",
    "        this_month = x\n",
    "    else:\n",
    "        this_month=x-12    \n",
    "    return this_month\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# define a bottom\n",
    "bottom = [0]*len(mgr[\"G27\"])\n",
    "\n",
    "# the monhtly survey average for all objects and locations\n",
    "monthly_fd = fd.groupby([\"loc_date\", \"date\"], as_index=False).agg(agg_pcs_quantity)\n",
    "monthly_fd.set_index(\"date\", inplace=True)\n",
    "m_fd = monthly_fd[unit_label].resample(\"M\").mean().fillna(0)\n",
    "\n",
    "# define the xaxis\n",
    "this_x = [i for i,x in  enumerate(m_fd.index)]\n",
    "\n",
    "# plot the monthly total survey average\n",
    "ax.bar(this_x, m_fd.to_numpy(), color=a_color, alpha=0.2, linewidth=1, edgecolor=\"teal\", width=1, label=\"Monthly survey average\") \n",
    "\n",
    "# plot the monthly survey average of the most common objects\n",
    "for i, a_group in enumerate(an_order): \n",
    "    \n",
    "    # define the axis\n",
    "    this_x = [i for i,x in  enumerate(mgr[a_group].index)]\n",
    "    \n",
    "    # collect the month\n",
    "    this_month = [x.month for i,x in enumerate(mgr[a_group].index)]\n",
    "    \n",
    "    # if i == 0 laydown the first bars\n",
    "    if i == 0:\n",
    "        ax.bar(this_x, mgr[a_group].to_numpy(), label=a_group, color=colors_palette[a_group], linewidth=1, alpha=0.6 ) \n",
    "    # else use the previous results to define the bottom\n",
    "    else:\n",
    "        bottom += mgr[an_order[i-1]].to_numpy()        \n",
    "        ax.bar(this_x, mgr[a_group].to_numpy(), bottom=bottom, label=a_group, color=colors_palette[a_group], linewidth=1, alpha=0.8)\n",
    "        \n",
    "# collect the handles and labels from the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# set the location of the x ticks\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i for i in np.arange(len(this_x))]))\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "# label the xticks by month\n",
    "axisticks = ax.get_xticks()\n",
    "labelsx = [months[new_month(x-1)] for x in  this_month]\n",
    "plt.xticks(ticks=axisticks, labels=labelsx)\n",
    "\n",
    "# make the legend\n",
    "# swap out codes for descriptions\n",
    "new_labels = [code_description_map.loc[x] for x in labels[1:]]\n",
    "new_labels = new_labels[::-1]\n",
    "\n",
    "# insert a label for the monthly average\n",
    "new_labels.insert(0,\"Monthly survey average\")\n",
    "handles = [handles[0], *handles[1:][::-1]]\n",
    "    \n",
    "plt.legend(handles=handles, labels=new_labels, bbox_to_anchor=(.5, -.05), loc=\"upper center\",  ncol=2, fontsize=14)       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey results and land use\n",
    "\n",
    "The land use mix is a unique representation of the type and amplitude of the economic activity and the environmental conditions around the survey location. The key indicators from the survey results are compared against the land use rates for a radius of 1500m from the survey location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An association is a relationship between the survey results and the land use profile that is unlikely due to chance. The magnitude of the relationship is neither defined nor linear. \n",
    "\n",
    "Ranked correlation is a non-parametric test to determine if there is a statistically significant relationship between land use and the objects identified in a litter survey. \n",
    "\n",
    "The method used is the Spearman’s rho or Spearmans ranked correlation coefficient. The test results are evaluated at p<0.05 for all valid lake samples in the survey area. \n",
    "\n",
    "1. Red/rose is a positive association\n",
    "2. Yellow is a negative association\n",
    "3. White means that p>0.05, there is no statistical basis to assume an association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "corr_data = fd[(fd.code.isin(m_common.index))&(fd.water_name_slug.isin(lakes_of_interest))].copy()\n",
    "\n",
    "alert_less_than_100 = len(corr_data.loc_date.unique()) <= 100\n",
    "\n",
    "if alert_less_than_100:\n",
    "    warning = F\"\"\"**There are less than 100 samples, proceed with caution. Beach litter surveys have alot of variance**\"\"\"\n",
    "else:\n",
    "    warning = \"\"\n",
    "\n",
    "association = F\"\"\"*__Below:__ {this_feature[\"name\"]} ranked correlation of the most common objects with respect to land use profile.\n",
    "For all valid lake samples n={len(corr_data.loc_date.unique())}.*\n",
    "\n",
    "{warning}\n",
    "\"\"\"\n",
    "md(association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# chart the results of test for association\n",
    "fig, axs = plt.subplots(len(m_common.index),len(luse_exp), figsize=(len(luse_exp)+7,len(m_common.index)+1), sharey=\"row\")\n",
    "\n",
    "# the test is conducted on the survey results for each code\n",
    "for i,code in enumerate(m_common.index):\n",
    "    # slice the data\n",
    "    data = corr_data[corr_data.code == code]\n",
    "    \n",
    "    # run the test on for each land use feature\n",
    "    for j, n in enumerate(luse_exp):       \n",
    "        # assign ax and set some parameters\n",
    "        ax=axs[i, j]\n",
    "        ax.grid(False)\n",
    "        ax.tick_params(axis=\"both\", which=\"both\",bottom=False,top=False,labelbottom=False, labelleft=False, left=False)\n",
    "        \n",
    "        # check the axis and set titles and labels       \n",
    "        if i == 0:\n",
    "            ax.set_title(F\"{n}\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.set_ylabel(F\"{code_description_map[code]}\", rotation=0, ha=\"right\", **ck.xlab_k14)\n",
    "            ax.set_xlabel(\" \")\n",
    "        else:\n",
    "            ax.set_xlabel(\" \")\n",
    "            ax.set_ylabel(\" \")\n",
    "        # run test\n",
    "        _, corr, a_p = sut.make_plot_with_spearmans(data, ax, n)\n",
    "        \n",
    "        # if siginficant set adjust color to direction\n",
    "        if a_p < 0.05:\n",
    "            if corr > 0:\n",
    "                ax.patch.set_facecolor(\"salmon\")\n",
    "                ax.patch.set_alpha(0.5)\n",
    "            else:\n",
    "                ax.patch.set_facecolor(\"palegoldenrod\")\n",
    "                ax.patch.set_alpha(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Key: &nbsp;if p>0.05 = white, &nbsp;if p < 0.05 and $\\rho$ > 0 = red, &nbsp;if p < 0.05 and $\\rho$ < 0 = yellow*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility of the objects found\n",
    "\n",
    "The utility type is based on the utilization of the object prior to it being discarded or object description if the original use is undetermined. Identified objects are classified into one of 260 predefined categories. The categories are grouped according to utilization or item description. \n",
    "\n",
    "*  **wastewater**: items released from water treatment plants includes items likely toilet flushed   \n",
    "*  **micro plastics (< 5mm)**: fragmented plastics and pre-production plastic resins \n",
    "*  **infrastructure**: items related to construction and maintenance of buildings, roads and water/power supplies \n",
    "*  **food and drink**: all materials related to consuming food and drink\n",
    "*  **agriculture**: primarily industrial sheeting i.e., mulch and row covers, greenhouses, soil fumigation, bale wraps. Includes hard plastics for agricultural fencing, flowerpots etc. \n",
    "*  **tobacco**: primarily cigarette filters, includes all smoking related material \n",
    "*  **recreation**: objects related to sports and leisure i.e., fishing, hunting, hiking etc.\n",
    "*  **packaging non food and drink**: packaging material not identified as food, drink nor tobacco related \n",
    "*  **plastic fragments**: plastic pieces of undetermined origin or use \n",
    "*  **personal items**: accessories, hygiene and clothing related \n",
    "\n",
    "See the annex for the complete list of objects identified, includes descriptions and group classification. The section [Code groups](codegroups) describes each code group in detail and provides a comprehensive list of all objects in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "cg_poft = F\"\"\"\n",
    "<br></br>\n",
    "__Below:__ {this_feature[\"name\"]} utility of objects found % of total by water feature. Fragmented objects with no clear identification remain classified by size.\n",
    "\"\"\"\n",
    "md(cg_poft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# code groups resluts aggregated by survey\n",
    "groups = [\"loc_date\",\"groupname\"]\n",
    "cg_t = fd.groupby([this_level,*groups], as_index=False).agg(agg_pcs_quantity)\n",
    "\n",
    "# the total per water feature\n",
    "cg_tq = cg_t.groupby(this_level).quantity.sum()\n",
    "\n",
    "# get the fail rates for each group per survey\n",
    "cg_t[\"fail\"]=False\n",
    "cg_t[\"fail\"] = cg_t.quantity.where(lambda x: x == 0, True)\n",
    "\n",
    "# aggregate all that for each municipality\n",
    "agg_this = {unit_label:\"median\", \"quantity\":\"sum\", \"fail\":\"sum\", \"loc_date\":\"nunique\"} \n",
    "cg_t = cg_t.groupby([this_level, \"groupname\"], as_index=False).agg(agg_this)\n",
    "\n",
    "# assign survey area total to each record\n",
    "for a_feature in cg_tq.index:\n",
    "    cg_t.loc[cg_t[this_level] == a_feature, \"f_total\"] = cg_tq.loc[a_feature]\n",
    "\n",
    "# get the percent of total for each group for each survey area\n",
    "cg_t[\"pt\"] = (cg_t.quantity/cg_t.f_total).round(2)\n",
    "\n",
    "# pivot that\n",
    "data_table = cg_t.pivot(columns=this_level, index=\"groupname\", values=\"pt\")\n",
    "\n",
    "# repeat for the survey area\n",
    "data_table[bassin_label] = sut.aggregate_to_group_name(fd, unit_label=unit_label, column=\"groupname\", name=bassin_label, val=\"pt\")\n",
    "\n",
    "# repeat for all the data\n",
    "data_table[top] = sut.aggregate_to_group_name(a_data, unit_label=unit_label, column=\"groupname\", name=top, val=\"pt\")\n",
    "\n",
    "data = data_table\n",
    "data.rename(columns={x:wname_wname.loc[x][0] for x in data.columns[:-2]}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axone = ax\n",
    "sns.heatmap(data , ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, cbar=False, fmt=\".0%\", linewidth=.1, square=True, linecolor=\"white\")\n",
    "\n",
    "axone.set_ylabel(\"\")\n",
    "axone.set_xlabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"both\", labeltop=False, labelbottom=True)\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90, fontsize=14)\n",
    "plt.setp(axone.get_yticklabels(), rotation=0, fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cg_medpcm = F\"\"\"\n",
    "<br></br>\n",
    "*__Below:__ {this_feature[\"name\"]} utility of objects found median {unit_label}. Fragmented objects with no clear identification remain classified by size.*\n",
    "\"\"\"\n",
    "md(cg_medpcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# median p/50m of all the water features\n",
    "data_table = cg_t.pivot(columns=\"water_name_slug\", index=\"groupname\", values=unit_label)\n",
    "\n",
    "# the survey area columns\n",
    "data_table[bassin_label] = sut.aggregate_to_group_name(fd, unit_label=unit_label, column=\"groupname\", name=bassin_label, val=\"med\")\n",
    "\n",
    "# column for all the surveys\n",
    "data_table[top] = sut.aggregate_to_group_name(a_data, unit_label=unit_label, column=\"groupname\", name=top, val=\"med\")\n",
    "\n",
    "# merge with data_table\n",
    "data = data_table\n",
    "data.rename(columns={x:wname_wname.loc[x][0] for x in data.columns[:-2]}, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axone = ax\n",
    "sns.heatmap(data , ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, fmt=\"g\", cbar=False, linewidth=.1, square=True, linecolor=\"white\")\n",
    "\n",
    "axone.set_xlabel(\"\")\n",
    "axone.set_ylabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"both\", labeltop=False, labelbottom=True)\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90, fontsize=14)\n",
    "plt.setp(axone.get_yticklabels(), rotation=0, fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rivers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "rivers = fd[fd.w_t == \"r\"].copy()\n",
    "r_smps = rivers.groupby([\"loc_date\", \"date\", \"location\", \"water_name_slug\"], as_index=False).agg(agg_pcs_quantity)\n",
    "l_smps = fd[fd.w_t == \"l\"].groupby([\"loc_date\",\"date\",\"location\", \"water_name_slug\"], as_index=False).agg(agg_pcs_quantity)\n",
    "\n",
    "chart_notes = F\"\"\"\n",
    "*__Left:__ {this_feature[\"name\"]} rivers, {start_date[:7]} through {end_date[:7]}, n={len(r_smps.loc_date.unique())}. {not_included} __Right:__ Summary data.*\n",
    "\"\"\"\n",
    "md(chart_notes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cs = r_smps[unit_label].describe().round(2)\n",
    "\n",
    "# add project totals\n",
    "cs[\"total objects\"] = r_smps.quantity.sum()\n",
    "\n",
    "# change the names\n",
    "csx = sut.change_series_index_labels(cs, sut.create_summary_table_index(unit_label, lang=\"EN\"))\n",
    "\n",
    "combined_summary = sut.fmt_combined_summary(csx, nf=[])\n",
    "\n",
    "# make the charts\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "\n",
    "aspec = fig.add_gridspec(ncols=11, nrows=3)\n",
    "\n",
    "ax = fig.add_subplot(aspec[:, :6])\n",
    "\n",
    "line_label = F\"{rate} median:{top}\"\n",
    "\n",
    "sns.scatterplot(data=l_smps, x=\"date\", y=unit_label, color=\"black\", alpha=0.4, label=\"Lake surveys\", ax=ax)\n",
    "sns.scatterplot(data=r_smps, x=\"date\", y=unit_label, color=\"red\", s=34, ec=\"white\",label=\"River surveys\", ax=ax)\n",
    "\n",
    "ax.set_ylim(-10,y_limit )\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "ax.xaxis.set_minor_locator(days)\n",
    "ax.xaxis.set_major_formatter(months_fmt)\n",
    "\n",
    "a_col = [this_feature[\"name\"], \"total\"]\n",
    "\n",
    "axone = fig.add_subplot(aspec[:, 7:])\n",
    "sut.hide_spines_ticks_grids(axone)\n",
    "\n",
    "table_five = sut.make_a_table(axone, combined_summary,  colLabels=a_col, colWidths=[.5,.25,.25],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_five.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers most common objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "riv_mcommon = F\"\"\"\n",
    "*__Below:__ {this_feature[\"name\"]} rivers, most common objects {unit_label}: median survey value*\n",
    "\"\"\"\n",
    "md(riv_mcommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the most common items rivers\n",
    "r_codes = rivers.groupby(\"code\").agg({\"quantity\":\"sum\", \"fail\":\"sum\", unit_label:\"median\"})\n",
    "r_codes[\"Fail rate\"] = (r_codes.fail/r_smps.loc_date.nunique()*100).astype(\"int\")\n",
    "\n",
    "# top ten\n",
    "r_byq = r_codes.sort_values(by=\"quantity\", ascending=False)[:10].index\n",
    "\n",
    "# most common\n",
    "r_byfail = r_codes[r_codes[\"Fail rate\"] > 49.99].index\n",
    "r_most_common = list(set(r_byq) | set(r_byfail))\n",
    "\n",
    "# format for display\n",
    "r_mc= r_codes.loc[r_most_common].copy()\n",
    "r_mc[\"item\"] = r_mc.index.map(lambda x: code_description_map.loc[x])\n",
    "r_mc.sort_values(by=\"quantity\", ascending=False, inplace=True)\n",
    "\n",
    "r_mc[\"% of total\"]=((r_mc.quantity/r_codes.quantity.sum())*100).astype(\"int\")\n",
    "r_mc[\"% of total\"] = r_mc[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "r_mc[\"quantity\"] = r_mc.quantity.map(lambda x: \"{:,}\".format(x))\n",
    "r_mc[\"Fail rate\"] = r_mc[\"Fail rate\"].map(lambda x: F\"{x}%\")\n",
    "r_mc[\"p/50m\"] = r_mc[unit_label].map(lambda x: F\"{np.ceil(x)}\")\n",
    "r_mc.rename(columns=cols_to_use, inplace=True)\n",
    "\n",
    "data=r_mc[[\"Item\",\"Quantity\", \"% of total\", \"Fail rate\", unit_label]]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(11,len(data)*.8))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_six = sut.make_a_table(axs, data.values,  colLabels=list(data.columns), colWidths=[.48, .13,.13,.13, .13], **{\"loc\":\"lower center\"})\n",
    "table_six.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex\n",
    "\n",
    "### Fragmented foams and plastics by size\n",
    "\n",
    "The table below contains the “Gfoam” and “Gfrags” components grouped for analysis. Objects labeled expanded foams are grouped as Gfoam and includes all expanded polystyrene foamed plastics > 0.5 cm.  Plastic pieces and objects made of combined plastic and foamed plastic materials > 0.5 cm. are grouped for analysis as Gfrags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "frag_foams = F\"\"\"\n",
    "*__Below:__ {this_feature[\"name\"]} fragmented foams and plastics by size group.*\n",
    "\"\"\"\n",
    "md(frag_foams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# collect the data before aggregating foams for all locations in the survye area\n",
    "# group by loc_date and code\n",
    "# Combine the different sizes of fragmented plastics and styrofoam\n",
    "# the codes for the foams\n",
    "some_foams = [\"G81\", \"G82\", \"G83\", \"G74\"]\n",
    "\n",
    "# the codes for the fragmented plastics\n",
    "some_frag_plas = list(before_agg[before_agg.groupname == \"plastic pieces\"].code.unique())\n",
    "\n",
    "fd_frags_foams = before_agg[(before_agg.code.isin([*some_frag_plas, *some_foams]))&(before_agg.location.isin(t[\"locations\"]))].groupby([\"loc_date\",\"code\"], as_index=False).agg(agg_pcs_quantity)\n",
    "fd_frags_foams = fd_frags_foams.groupby(\"code\").agg(agg_pcs_median)\n",
    "\n",
    "# add code description and format for printing\n",
    "fd_frags_foams[\"item\"] = fd_frags_foams.index.map(lambda x: code_description_map.loc[x])\n",
    "fd_frags_foams[\"% of total\"] = (fd_frags_foams.quantity/fd.quantity.sum()*100).round(2)\n",
    "fd_frags_foams[\"% of total\"] = fd_frags_foams[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "fd_frags_foams[\"quantity\"] = fd_frags_foams[\"quantity\"].map(lambda x: F\"{x:,}\")\n",
    "\n",
    "# table data\n",
    "data = fd_frags_foams[[\"item\",unit_label, \"quantity\", \"% of total\"]]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(len(data.columns)*2.4,len(data)*.7))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_seven = sut.make_a_table(axs,data.values,  colLabels=data.columns, colWidths=[.6, .13, .13, .13], a_color=a_color)\n",
    "table_seven.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_seven.set_fontsize(14)\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The survey locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# display the survey locations\n",
    "disp_columns = [\"latitude\", \"longitude\", \"city\"]\n",
    "disp_beaches = dfBeaches.loc[t[\"locations\"]][disp_columns]\n",
    "disp_beaches.reset_index(inplace=True)\n",
    "disp_beaches.rename(columns={\"slug\":\"location\"}, inplace=True)\n",
    "disp_beaches.set_index(\"location\", inplace=True, drop=True)\n",
    "\n",
    "disp_beaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inventory of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "complete_inventory = code_totals[code_totals.quantity>0][[\"item\", \"groupname\", \"quantity\", \"% of total\",\"fail rate\"]]\n",
    "complete_inventory.sort_values(by=\"quantity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
