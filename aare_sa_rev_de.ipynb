{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# This is a report using the data from IQAASL.\n",
    "# IQAASL was a project funded by the Swiss Confederation\n",
    "# It produces a summary of litter survey results for a defined region.\n",
    "# These charts serve as the models for the development of plagespropres.ch\n",
    "# The data is gathered by volunteers.\n",
    "# Please remember all copyrights apply, please give credit when applicable\n",
    "# The repo is maintained by the community effective January 01, 2022\n",
    "# There is ample opportunity to contribute, learn and teach\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# Dies ist ein Bericht, der die Daten von IQAASL verwendet.\n",
    "# IQAASL war ein von der Schweizerischen Eidgenossenschaft finanziertes Projekt.\n",
    "# Es erstellt eine Zusammenfassung der Ergebnisse der Littering-Umfrage für eine bestimmte Region.\n",
    "# Diese Grafiken dienten als Vorlage für die Entwicklung von plagespropres.ch.\n",
    "# Die Daten werden von Freiwilligen gesammelt.\n",
    "# Bitte denken Sie daran, dass alle Copyrights gelten, bitte geben Sie den Namen an, wenn zutreffend.\n",
    "# Das Repo wird ab dem 01. Januar 2022 von der Community gepflegt.\n",
    "# Es gibt reichlich Gelegenheit, etwas beizutragen, zu lernen und zu lehren.\n",
    "# Kontakt dev@hammerdirt.ch\n",
    "\n",
    "# Il s'agit d'un rapport utilisant les données de IQAASL.\n",
    "# IQAASL était un projet financé par la Confédération suisse.\n",
    "# Il produit un résumé des résultats de l'enquête sur les déchets sauvages pour une région définie.\n",
    "# Ces tableaux ont servi de modèles pour le développement de plagespropres.ch\n",
    "# Les données sont recueillies par des bénévoles.\n",
    "# N'oubliez pas que tous les droits d'auteur s'appliquent, veuillez indiquer le crédit lorsque cela est possible.\n",
    "# Le dépôt est maintenu par la communauté à partir du 1er janvier 2022.\n",
    "# Il y a de nombreuses possibilités de contribuer, d'apprendre et d'enseigner.\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# sys, file and nav packages:\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, time\n",
    "from babel.dates import format_date, format_datetime, format_time, get_month_names\n",
    "import locale\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# charting:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "# home brew utitilties\n",
    "import resources.chart_kwargs as ck\n",
    "import resources.sr_ut as sut\n",
    "\n",
    "# images and display\n",
    "from IPython.display import Markdown as md\n",
    "from myst_nb import glue\n",
    "\n",
    "# set the locale to the language desired\n",
    "date_lang =  'de_DE.utf8'\n",
    "language = \"DE\"\n",
    "locale.setlocale(locale.LC_ALL, date_lang)\n",
    "\n",
    "# the date is in iso standard:\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "# it gets changed to german format\n",
    "german_date_format = \"%d.%m.%Y\"\n",
    "\n",
    "# set some parameters:\n",
    "start_date = \"2020-03-01\"\n",
    "end_date =\"2021-05-31\"\n",
    "start_end = [start_date, end_date]\n",
    "\n",
    "# The fail rate is 50%, that is objects that\n",
    "# are found in more than 50% of the samples\n",
    "# are considered common or among the most common\n",
    "a_fail_rate = 50\n",
    "\n",
    "# the units of the repor\n",
    "unit_label = \"p/100 m\"\n",
    "\n",
    "# charting and colors\n",
    "sns.set_style(\"whitegrid\")\n",
    "table_row = \"saddlebrown\"\n",
    "\n",
    "# colors for gradients\n",
    "cmap2 = ck.cmap2\n",
    "colors_palette = ck.colors_palette\n",
    "\n",
    "## !! Begin Note book variables !!\n",
    "\n",
    "# Changing these variables produces different reports\n",
    "# Call the map image for the area of interest\n",
    "bassin_map = \"resources/maps/survey_areas/aare_scaled.jpeg\"\n",
    "\n",
    "# the label for the aggregation of all data in the region\n",
    "top = \"Alle Erhebungsgebiete\"\n",
    "\n",
    "# define the feature level and components\n",
    "# the feature of interest is the Aare (aare) at the river basin (river_bassin) level.\n",
    "# the label for charting is called 'name'\n",
    "this_feature = {'slug':'aare', 'name':\"Erhebungsgebiet Aare\", 'level':'river_bassin'}\n",
    "\n",
    "# these are the smallest aggregated components\n",
    "# choices are water_name_slug=lake or river, city or location at the scale of a river bassin \n",
    "# water body or lake maybe the most appropriate\n",
    "this_level = 'water_name_slug'\n",
    "\n",
    "# identify the lakes of interest for the survey area\n",
    "lakes_of_interest = [\"neuenburgersee\", \"thunersee\", \"bielersee\", \"brienzersee\"]\n",
    "\n",
    "# !! End note book variables !!\n",
    "\n",
    "# column names for the dimensions table output\n",
    "dims_table_columns={\n",
    "    \"samples\":\"Erhebungen\",\n",
    "    \"quantity\":\"Objekte\",\n",
    "    \"total_w\":\"Gesamt-kg\",\n",
    "    \"mac_plast_w\":\"kg Plastik\",\n",
    "    \"area\":\"m²\",\n",
    "    \"length\":\"Meter\"\n",
    "}\n",
    "\n",
    "# !! explanatory variabales, code definitions, language specific\n",
    "\n",
    "# Survey location details (GPS, city, land use)\n",
    "dfBeaches = pd.read_csv(\"resources/beaches_with_land_use_rates.csv\")\n",
    "\n",
    "# Object code definitions, labels and material type\n",
    "dfCodes = pd.read_csv(\"resources/codes_with_group_names_2015.csv\")\n",
    "\n",
    "# Survey dimensions and weights\n",
    "dfDims = pd.read_csv(\"resources/corrected_dims.csv\")\n",
    "\n",
    "# set the index of the beach data to location slug\n",
    "dfBeaches.set_index(\"slug\", inplace=True)\n",
    "\n",
    "# set the index of code data to code\n",
    "dfCodes.set_index(\"code\", inplace=True)\n",
    "\n",
    "# the surveyor designated the object as aluminum instead of metal\n",
    "dfCodes.loc[\"G708\", \"material\"] = \"Metal\"\n",
    "\n",
    "# language specific\n",
    "# importing german code descriptions\n",
    "de_codes = pd.read_csv(\"resources/codes_german_Version_1.csv\")\n",
    "de_codes.set_index(\"code\", inplace=True)\n",
    "\n",
    "# use the german translation of the code descriptions\n",
    "for x in dfCodes.index:\n",
    "    dfCodes.loc[x, \"description\"] = de_codes.loc[x, \"german\"]\n",
    "    \n",
    "# there are long code descriptions that may need to be shortened for display\n",
    "codes_to_change = [\n",
    "    [\"G704\", \"description\", \"Seilbahnbürste\"],\n",
    "    [\"Gfrags\", \"description\", \"Fragmentierte Kunststoffstücke\"],\n",
    "    [\"G30\", \"description\", \"Snack-Verpackungen\"],\n",
    "    [\"G124\", \"description\", \"Kunststoff-oder Schaumstoffprodukte\"],\n",
    "    [\"G87\", \"description\", \"Abdeckklebeband / Verpackungsklebeband\"],\n",
    "    [\"G3\",\"description\",\"Einkaufstaschen, Shoppingtaschen\"],\n",
    "    [\"G33\", \"description\", \"Einwegartikel; Tassen/Becher & Deckel\"],\n",
    "    [\"G31\", \"description\", \"Schleckstengel, Stengel von Lutscher\"],\n",
    "    [\"G211\", \"description\", \"Sonstiges medizinisches Material\"],\n",
    "    [\"G904\", \"description\", \"Feuerwerkskörper; Raketenkappen\"],\n",
    "    [\"G940\", \"description\", \"Schaumstoff EVA (flexibler Kunststoff)\"],\n",
    "    [\"G178\", \"description\", \"Kronkorken, Lasche von Dose/Ausfreisslachen\"],\n",
    "    [\"G74\", \"description\", \"Schaumstoffverpackungen/Isolierung\"],\n",
    "    [\"G941\", \"description\", \"Verpackungsfolien, nicht für Lebensmittel\"]\n",
    "]\n",
    "\n",
    "# apply changes\n",
    "for x in codes_to_change:\n",
    "    dfCodes = sut.shorten_the_value(x, dfCodes)\n",
    "    \n",
    "# translate the material column to german\n",
    "dfCodes[\"material\"] = dfCodes.material.map(lambda x: sut.mat_ge[x]) \n",
    "\n",
    "# make a map to the code descriptions\n",
    "code_description_map = dfCodes.description\n",
    "\n",
    "# make a map to the code materials\n",
    "code_material_map = dfCodes.material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(aaresa)=\n",
    "# Aare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "map_caption = [\n",
    "    \"Karte des Erhebungsgebiets März 2020 bis Mai 2021. \",\n",
    "    \"Der Durchmesser der Punktsymbole entspricht dem Median der\",\n",
    "    \"Abfallobjekte pro 100 Meter (p/100 m) am jeweiligen Erhebungsort.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} resources/maps/survey_areas/aare_scaled.jpeg\n",
    "---\n",
    "name: aare_survey_area_map\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_map>` Karte des Erhebungsgebiets März 2020 bis Mai 2021. Der Durchmesser der Punktsymbole entspricht dem Median der Abfallobjekte pro 100 Meter (p/100 m) am jeweiligen Erhebungsort.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erhebungsorte und Landnutzungsprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 209\u001b[0m\n\u001b[1;32m    206\u001b[0m summary_data \u001b[38;5;241m=\u001b[39m AdministrativeSummary(data\u001b[38;5;241m=\u001b[39mfd, label\u001b[38;5;241m=\u001b[39mthis_feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeach_data\u001b[39m\u001b[38;5;124m\"\u001b[39m:dfBeaches})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# collects the names of the survey location\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m a_summary \u001b[38;5;241m=\u001b[39m \u001b[43msummary_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummaryObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m rivers \u001b[38;5;241m=\u001b[39m summary_data\u001b[38;5;241m.\u001b[39mriversOfInterest()\n\u001b[1;32m    212\u001b[0m lakes \u001b[38;5;241m=\u001b[39m summary_data\u001b[38;5;241m.\u001b[39mlakesOfInterest()\n",
      "Cell \u001b[0;32mIn [10], line 191\u001b[0m, in \u001b[0;36mAdministrativeSummary.summaryObject\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummaryObject\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):        \n\u001b[1;32m    190\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresultsObject()\n\u001b[0;32m--> 191\u001b[0m     pop_values \u001b[38;5;241m=\u001b[39m sut\u001b[38;5;241m.\u001b[39mmake_table_values(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulationKeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, col_nunique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_nunique_city, col_sum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_sum_pop)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocationsOfInterest()\n\u001b[1;32m    193\u001b[0m     t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocations_of_interest\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocations_of_interest\n",
      "Cell \u001b[0;32mIn [10], line 158\u001b[0m, in \u001b[0;36mAdministrativeSummary.populationKeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m locs \u001b[38;5;241m=\u001b[39m checkInitiateAttribute(check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocations_of_interest, data\u001b[38;5;241m=\u001b[39mdata, atype\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray), a_method\u001b[38;5;241m=\u001b[39muniqueValues)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     popmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_beaches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m[locs][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_population]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat did not work\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "def thereIsData(data=False, atype=(pd.DataFrame, )):\n",
    "    # checkes that the provided data is a certain type\n",
    "    if isinstance(data, atype):\n",
    "        return data\n",
    "    else:\n",
    "        raise TypeError(f\"There is no data or it is not the right type: is_instance({data}, {atype}).\")\n",
    "\n",
    "def loadData(filename):\n",
    "    # loads data from a .csv\n",
    "    filename = thereIsData(data=filename, atype=(str,))\n",
    "    \n",
    "    try:\n",
    "        a = pd.read_csv(filename)        \n",
    "    except OSError:\n",
    "        print(\"The file could not be read, is this the right file extension?\")\n",
    "        raise\n",
    "    return a\n",
    "\n",
    "def changeColumnNames(data, columns={}):\n",
    "    # changes the column names of a data frame\n",
    "    data = thereIsData(data=data, atype=(pd.DataFrame, ))\n",
    "    cols = thereIsData(data=columns, atype=(dict, ))\n",
    "    \n",
    "    try:\n",
    "        a = data.rename(columns=columns)\n",
    "    except ValueError:\n",
    "        print(\"The columns did not go with the data\")\n",
    "        raise\n",
    "    return a\n",
    "\n",
    "def makeEventIdColumn(data, feature_level, these_features=[], index_name=\"loc_date\", index_prefix=\"location\", index_suffix=\"date\", **kwargs):\n",
    "    # Combines the location and date column into one str: \"slug-date\"\n",
    "    # makes it possible ot group records by event\n",
    "    # converts string dates to timestamps and localizes to UTC\n",
    "    data = thereIsData(data=data, atype=(pd.DataFrame, ))\n",
    "    feature_level = thereIsData(data=feature_level, atype=(str, ))\n",
    "    these_features = thereIsData(data=these_features, atype=(list, np.ndarray))\n",
    "    \n",
    "    try:\n",
    "        sliced_data = data[data[feature_level].isin(these_features)].copy()    \n",
    "        sliced_data[index_name] = list(zip(sliced_data[index_prefix].values, sliced_data[index_suffix].values))\n",
    "        sliced_data[\"date\"] = pd.to_datetime(sliced_data[\"date\"], format=date_format).dt.tz_localize('UTC')\n",
    "    except RuntimeError:\n",
    "        print(\"The pandas implementation did not function\")\n",
    "        raise\n",
    "    \n",
    "    return sliced_data\n",
    "    \n",
    "def featureData(filename, feature_level, these_features=[], columns=False, language=\"EN\"):\n",
    "    # makes the feature data to be explored    \n",
    "    data = loadData(filename)\n",
    "    \n",
    "    if columns != False:\n",
    "        data = changeColumnNames(data, columns=columns)\n",
    "    if language == \"DE\":\n",
    "        data[\"groupname\"] = data[\"groupname\"].map(lambda x: sut.group_names_de[x])\n",
    "    a = makeEventIdColumn(data, feature_level, these_features=these_features)\n",
    "    \n",
    "    return a, data\n",
    "\n",
    "def convert_case(str_camelcase):\n",
    "    # This function takes in a string in camelCase and converts it to snake_case\n",
    "    str_camelcase = thereIsData(data=str_camelcase, atype=(str, ))\n",
    "    str_snake_case = \"\"\n",
    "    for ele in list(str_camelcase):\n",
    "        if ele.islower():\n",
    "            str_snake_case = str_snake_case + ele\n",
    "        else:\n",
    "            str_snake_case = str_snake_case + \"_\" + ele.lower()\n",
    "    return str_snake_case\n",
    "\n",
    "\n",
    "def checkInitiateAttribute(data=False, check=False, atype=(list, np.ndarray), a_method=None, **kwargs):\n",
    "    # check the data type of the requested element against the required data type\n",
    "    # if check the data is returned, else <a_method> will be applied to <data>\n",
    "    # and checked again.    \n",
    "    if isinstance(check, atype):\n",
    "        return check\n",
    "    else:\n",
    "        try:\n",
    "            new_data = a_method(data)\n",
    "            check_again = checkInitiateAttribute(check=new_data, data=new_data, atype=atype, a_method=a_method, **kwargs)\n",
    "            return check_again\n",
    "            \n",
    "        except ValueError:\n",
    "            print(\"neither the data nor the method worked\")\n",
    "            raise\n",
    "            \n",
    "def uniqueValues(data):\n",
    "    # method to pass pd.series.unique as a variable\n",
    "    return data.location.unique()\n",
    "\n",
    "def dateToYearAndMonth(python_date_object, fmat='wide', lang=\"\"):\n",
    "    a_date = thereIsData(data=python_date_object, atype=(datetime, ))\n",
    "    amonth = a_date.month\n",
    "    a_year = a_date.year\n",
    "    amonth_foreign = get_month_names(fmat, locale=lang)[amonth]\n",
    "    \n",
    "    return f'{amonth_foreign} {a_year}'\n",
    "    \n",
    "def thousandsSeparator(aninteger, lang):\n",
    "    \n",
    "    astring = \"{:,}\".format(aninteger)\n",
    "    \n",
    "    if lang == \"DE\":\n",
    "        astring = astring.replace(\",\", \" \")        \n",
    "        \n",
    "    return astring\n",
    "\n",
    "\n",
    "class Beaches:\n",
    "    \"\"\"The dimendsional and geo data for each survey location\"\"\"\n",
    "    def __init__(self, beach_data: pd.DataFrame=None):\n",
    "        self.df_beaches = beach_data\n",
    "    \n",
    "\n",
    "class AdministrativeSummary(Beaches):\n",
    "       \n",
    "    col_nunique_qty=[\"location\", \"loc_date\", \"city\"]\n",
    "    col_sum_qty = [\"quantity\"]\n",
    "    col_population = [\"city\", \"population\"]\n",
    "    col_sum_pop = [\"population\"]\n",
    "    col_nunique_city = [\"city\"]\n",
    "    locations_of_interest = None\n",
    "    lakes_of_interest = None\n",
    "    rivers_of_interest = None\n",
    "    \n",
    "    def __init__(self, data = None, label=None, **kwargs):\n",
    "        super().__init__()  \n",
    "        \n",
    "        self.data = data\n",
    "        self.label = label\n",
    "          \n",
    "        \n",
    "    def locationsOfInterest(self, **kwargs):        \n",
    "        data = thereIsData(self.data, (pd.DataFrame))\n",
    "        locations = checkInitiateAttribute(check=self.locations_of_interest, data=data, atype=(list, np.ndarray), a_method=uniqueValues, **kwargs)\n",
    "                \n",
    "        self.locations_of_interest = locations\n",
    "    \n",
    "    def resultsObject(self, col_nunique=None, col_sum=None, **kwargs):\n",
    "        data = thereIsData(self.data, (pd.DataFrame))\n",
    "        \n",
    "        if not col_nunique:\n",
    "            col_nunique=self.col_nunique_qty\n",
    "        if not col_sum:\n",
    "            col_sum=self.col_sum_qty\n",
    "            \n",
    "        t = sut.make_table_values(data, col_nunique=col_nunique, col_sum=col_sum)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    def populationKeys(self):\n",
    "        data = thereIsData(self.data, (pd.DataFrame))\n",
    "        locs = checkInitiateAttribute(check=self.locations_of_interest, data=data, atype=(list, np.ndarray), a_method=uniqueValues)\n",
    "        \n",
    "        try:\n",
    "            popmap = self.df_beaches.loc[locs][self.col_population].drop_duplicates()\n",
    "        except TypeError as e:\n",
    "            print(\"that did not work\")\n",
    "        \n",
    "        return popmap\n",
    "    \n",
    "    def lakesOfInterest(self):\n",
    "        data = thereIsData(self.data, (pd.DataFrame))\n",
    "        locs = checkInitiateAttribute(check=self.locations_of_interest, data=data, atype=(list, np.ndarray), a_method=uniqueValues)\n",
    "        \n",
    "               \n",
    "        if not isinstance(self.lakes_of_interest, list):\n",
    "            mask = (self.df_beaches.index.isin(locs))&(self.df_beaches.water == \"l\")\n",
    "            d = self.df_beaches.loc[mask][\"water_name\"].unique()\n",
    "            self.lakes_of_interest = d\n",
    "            return d\n",
    "        else:\n",
    "            return self.lakes_of_interest\n",
    "        \n",
    "    def riversOfInterest(self):        \n",
    "        data = thereIsData(self.data, (pd.DataFrame))        \n",
    "        locs = checkInitiateAttribute(check=self.locations_of_interest, data=data, atype=(list, np.ndarray), a_method=uniqueValues)      \n",
    "        \n",
    "        if not isinstance(self.rivers_of_interest, list):\n",
    "            mask = (self.df_beaches.index.isin(locs))&(self.df_beaches.water == \"r\")\n",
    "            d = self.df_beaches.loc[mask][\"water_name\"].unique()\n",
    "            self.rivers_of_interest = d\n",
    "            return d\n",
    "        else:\n",
    "            return self.rivers_of_interest\n",
    "        \n",
    "    def summaryObject(self, **kwargs):        \n",
    "        t = self.resultsObject()\n",
    "        pop_values = sut.make_table_values(self.populationKeys(), col_nunique=self.col_nunique_city, col_sum=self.col_sum_pop)\n",
    "        self.locationsOfInterest()\n",
    "        t[\"locations_of_interest\"] = self.locations_of_interest\n",
    "       \n",
    "        t.update(pop_values)\n",
    "        \n",
    "        return t\n",
    "\n",
    "# the survey data\n",
    "filename = \"resources/checked_sdata_eos_2020_21.csv\"\n",
    "columns={\"% to agg\":\"% agg\", \"% to recreation\": \"% recreation\", \"% to woods\":\"% woods\", \"% to buildings\":\"% buildings\", \"p/100m\":\"p/100 m\"}\n",
    "fd, a_data = featureData(filename, this_feature[\"level\"], these_features=[this_feature[\"slug\"]], columns=columns, language=\"DE\")\n",
    "\n",
    "\n",
    "# collects the summarized values for all the data in the region\n",
    "summary_data = AdministrativeSummary(data=fd, label=this_feature[\"name\"], **{\"beach_data\":dfBeaches})\n",
    "\n",
    "# collects the names of the survey location\n",
    "a_summary = summary_data.summaryObject()\n",
    "\n",
    "rivers = summary_data.riversOfInterest()\n",
    "lakes = summary_data.lakesOfInterest()\n",
    "        \n",
    "# string objects for display\n",
    "obj_string = thousandsSeparator(a_summary[\"quantity\"], language)\n",
    "surv_string = \"{:,}\".format(a_summary[\"loc_date\"])\n",
    "pop_string = thousandsSeparator(int(a_summary[\"population\"]), language)\n",
    "\n",
    "# make strings\n",
    "date_quantity_context = F\"Im Zeitraum von {dateToYearAndMonth(datetime.strptime(start_date, date_format), lang=date_lang)}  bis {dateToYearAndMonth(datetime.strptime(end_date, date_format), lang= date_lang)} wurden im Rahmen von {surv_string} Datenerhebungen insgesamt {obj_string } Objekte entfernt und identifiziert.\"\n",
    "geo_context = F\"Die Ergebnisse des {this_feature['name']} umfassen {a_summary['location']} Orte, {a_summary['city']} Gemeinden und eine Gesamtbevölkerung von etwa {pop_string} Einwohnenden.\"\n",
    "\n",
    "# lists of landmarks of interest\n",
    "munis_joined = \", \".join(sorted(summary_data.populationKeys()[\"city\"]))\n",
    "lakes_joined = \", \".join(sorted(lakes))\n",
    "rivers_joined = \", \".join(sorted(rivers))\n",
    "\n",
    "# put that all together:\n",
    "lake_string = F\"\"\"\n",
    "{date_quantity_context} {geo_context }\n",
    "\n",
    "*Seen:*\\n\\n>{lakes_joined}\n",
    "\n",
    "*Fliessgewässer:*\\n\\n>{rivers_joined}\n",
    "\n",
    "*Gemeinden:*\\n\\n>{munis_joined}\n",
    "\"\"\"\n",
    "md(lake_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landnutzungsprofil der Erhebungsorte\n",
    "\n",
    "Das Landnutzungsprofil zeigt, welche Nutzungen innerhalb eines Radius von 1500 m um jeden Erhebungsort dominieren. Flächen werden einer von den folgenden vier Kategorien zugewiesen:\n",
    "\n",
    "* Fläche, die von Gebäuden eingenommen wird in %\n",
    "* Fläche, die dem Wald vorbehalten ist in %\n",
    "* Fläche, die für Aktivitäten im Freien genutzt wird in %\n",
    "* Fläche, die von der Landwirtschaft genutzt wird in %\n",
    "\n",
    "Strassen (inkl. Wege) werden als Gesamtzahl der Strassenkilometer innerhalb eines Radius von 1500 m angegeben.\n",
    "\n",
    "Es wird zudem angegeben, wie viele Flüsse innerhalb eines Radius von 1500 m um den Erhebungsort herum in das Gewässer münden.\n",
    "\n",
    "Das Verhältnis der gefundenen Abfallobjekte unterscheidet sich je nach Landnutzungsprofil. Das Verhältnis gibt daher einen Hinweis auf die ökologischen und wirtschaftlichen Bedingungen um den Erhebungsort.\n",
    "\n",
    "Für weitere Informationen siehe *[17 Landnutzungsprofil](luseprofile)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# land use characteristics\n",
    "# the ratio of samples with respect to the different land use characteristics for each survey area\n",
    "# the data to use is the unique combinations of loc_date and the land_use charcteristics of each location\n",
    "# land use explanatory variables are in the :\n",
    "# land_use_columns = [\"% buildings\", \"% recreation\", \"% agg\", \"% woods\", \"streets km\", \"intersects\"]\n",
    "\n",
    "def empiricalCDF(anarray):\n",
    "    data = thereIsData(anarray, (list, np.ndarray))\n",
    "    y = np.arange(1, len(data)+1)/float(len(data))\n",
    "    x = sorted(data)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def ecdfOfaColumn(data, column=\"\"):\n",
    "    data = thereIsData(data, (pd.DataFrame,))\n",
    "    col = thereIsData(column, (list, np.ndarray))\n",
    "    \n",
    "    anarray=data[col].values\n",
    "    \n",
    "    x,y = empiricalCDF(anarray)\n",
    "    \n",
    "    return {\"column\":col, \"x\":x, \"y\":y} \n",
    "    \n",
    "\n",
    "\n",
    "class LandUseProfile:\n",
    "    \n",
    "    def __init__(self, data=None, index_column=\"loc_date\", aggregation_level=this_feature[\"level\"], feature_of_interest=this_feature[\"slug\"], land_use_columns = [\"% buildings\", \"% recreation\", \"% agg\", \"% woods\", \"streets km\", \"intersects\"],  **kwargs):\n",
    "        self.data = data\n",
    "        self.land_use_columns = land_use_columns\n",
    "        self.aggregation_level = aggregation_level\n",
    "        self.index_column= index_column\n",
    "        self.feature_of_interest = feature_of_interest\n",
    "        super().__init__()\n",
    "        \n",
    "    def byIndexColumn(self):\n",
    "        data = thereIsData(data=self.data, atype=(pd.DataFrame, ))\n",
    "        columns = [self.index_column, self.aggregation_level, *self.land_use_columns]\n",
    "        d = data[columns].drop_duplicates()\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def featureOfInterest(self):\n",
    "        data = thereIsData(data=self.data, atype=(pd.DataFrame, ))\n",
    "        d_indexed = self.byIndexColumn()\n",
    "        d =d_indexed[d_indexed[self.aggregation_level] == self.feature_of_interest]\n",
    "        \n",
    "        return d\n",
    "\n",
    "land_use_columns = [\"% buildings\", \"% recreation\", \"% agg\", \"% woods\", \"streets km\", \"intersects\"]    \n",
    "project_profile = LandUseProfile(data=a_data).byIndexColumn()\n",
    "feature_profile = LandUseProfile(data=fd).featureOfInterest()\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9,8), sharey=\"row\")\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "for i, n in enumerate(land_use_columns):\n",
    "    r = i%2\n",
    "    c = i%3\n",
    "    ax=axs[r,c]\n",
    "    \n",
    "    # the value of landuse feature n for the survey area:\n",
    "    data=feature_profile[n].values\n",
    "    xs, ys = empiricalCDF(data)   \n",
    "    sns.lineplot(x=xs, y=ys, ax=ax, label=summary_data.label)\n",
    "    \n",
    "    # the value of the land use feature n for all the data\n",
    "    testx, testy = empiricalCDF(project_profile[n].values)\n",
    "    sns.lineplot(x=testx, y=testy, ax=ax, label=top, color=\"magenta\")\n",
    "    \n",
    "    # get the median from the data\n",
    "    the_median = np.median(data)\n",
    "    \n",
    "    # plot the median and drop horzontal and vertical lines\n",
    "    ax.scatter([the_median], 0.5, color=\"red\",s=50, linewidth=2, zorder=100, label=\"Median\")\n",
    "    ax.vlines(x=the_median, ymin=0, ymax=0.5, color=\"red\", linewidth=2)\n",
    "    ax.hlines(xmax=the_median, xmin=0, y=0.5, color=\"red\", linewidth=2)\n",
    "    \n",
    "    if i <= 3:\n",
    "        if c == 0:            \n",
    "            ax.set_ylabel(\"Ratio of samples\", **ck.xlab_k)\n",
    "            ax.yaxis.set_major_locator(MultipleLocator(.1))\n",
    "        ax.xaxis.set_major_formatter(ticker.PercentFormatter(1.0, 0, \"%\"))        \n",
    "    else:\n",
    "        pass      \n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()    \n",
    "    ax.set_xlabel(list(sut.luse_ge.values())[i], **ck.xlab_k)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9, hspace=.3)\n",
    "plt.suptitle(\"Landnutzung im Umkries von 1 500 m um den Erhebungsort\", ha=\"center\", y=1, fontsize=16)\n",
    "fig.legend(handles, labels, bbox_to_anchor=(.5,.94), loc=\"center\", ncol=3) \n",
    "\n",
    "glue(\"aare_survey_area_landuse\", fig, display=False)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_landuse\n",
    "---\n",
    "name: 'aare_survey_area_landuse'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_landuse>` Landnutzungsprofil der Erhebungsorte. Verteilung der Erhebungen in Bezug auf die Landnutzung. LWS = Landwirtschaft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kumulative Gesamtmengen nach Gewässer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# aggregate the dimensional data\n",
    "agg_dims = {\"total_w\":\"sum\", \"mac_plast_w\":\"sum\", \"area\":\"sum\", \"length\":\"sum\"}\n",
    "\n",
    "dims_parameters = dict(this_level=this_level, \n",
    "                       locations=fd.location.unique(), \n",
    "                       start_end=start_end, \n",
    "                       agg_dims=agg_dims)\n",
    "\n",
    "dims_table = sut.gather_dimensional_data(dfDims, **dims_parameters)\n",
    "\n",
    "# map the qauntity to the dimensional data\n",
    "q_map = fd.groupby(this_level).quantity.sum()\n",
    "\n",
    "# collect the number of samples from the survey total data:\n",
    "for name in dims_table.index:\n",
    "    dims_table.loc[name, \"samples\"] = fd[fd[this_level] == name].loc_date.nunique()\n",
    "    dims_table.loc[name, \"quantity\"] = q_map[name]\n",
    "\n",
    "# map the proper name of the lake to the slug value\n",
    "wname_wname = dfBeaches[[\"water_name_slug\",\"water_name\"]].reset_index(drop=True).drop_duplicates().set_index(\"water_name_slug\")\n",
    "comp_labels = {x:wname_wname.loc[x][0] for x in fd[this_level].unique()}\n",
    "\n",
    "# add the proper names for display\n",
    "dims_table[\"water_feature\"] = dims_table.index.map(lambda x: comp_labels[x])\n",
    "dims_table.set_index(\"water_feature\", inplace=True)   \n",
    "\n",
    "# get the sum of all survey areas\n",
    "dims_table.loc[this_feature[\"name\"]]= dims_table.sum(numeric_only=True, axis=0)\n",
    "\n",
    "# for display\n",
    "dims_table.sort_values(by=[\"quantity\"], ascending=False, inplace=True)\n",
    "dims_table.rename(columns=dims_table_columns, inplace=True)\n",
    "\n",
    "# format kilos and text strings\n",
    "dims_table[\"kg Plastik\"] = dims_table[\"kg Plastik\"]/1000\n",
    "dims_table[[\"m²\", \"Meter\", \"Erhebungen\", \"Objekte\"]] = dims_table[[\"m²\", \"Meter\", \"Erhebungen\", \"Objekte\"]].applymap(lambda x: thousandsSeparator(int(x), language))\n",
    "dims_table[[\"kg Plastik\", \"Gesamt-kg\"]] = dims_table[[\"kg Plastik\", \"Gesamt-kg\"]].applymap(lambda x: \"{:.2f}\".format(x))\n",
    "\n",
    "# make table\n",
    "data = dims_table.reset_index()\n",
    "colLabels = data.columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(colLabels)*1.8,len(data)*.7))\n",
    "sut.hide_spines_ticks_grids(ax)\n",
    "\n",
    "table_one = sut.make_a_table(ax, data.values, colLabels=colLabels, colWidths=[.28, *[.12]*6], a_color=table_row)\n",
    "table_one.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "plt.tight_layout()\n",
    "glue(\"aare_survey_area_dimensional_summary\", fig, display=False)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_dimensional_summary\n",
    "---\n",
    "name: 'aare_survey_area_dimensional_summary'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_dimensional_summary>` Die kumulierten Gewichte und Merkmale für das Erhebungsgebiet Aare nach Gewässern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Erhebungsergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the surveys to chart\n",
    "# common aggregations: sum the pcs/m and quantity per event and location\n",
    "agg_pcs_quantity = {unit_label:\"sum\", \"quantity\":\"sum\"}\n",
    "\n",
    "# daily survey totals\n",
    "dt_all = fd.groupby([\"loc_date\",\"location\",this_level, \"city\",\"date\"], as_index=False).agg(agg_pcs_quantity)\n",
    "fd_dindex = dt_all.copy()\n",
    "\n",
    "# Daily totals from all other locations\n",
    "ots = dict(level_to_exclude=this_feature[\"level\"], components_to_exclude=fd[this_feature[\"level\"]].unique())\n",
    "dts_date = sut.the_other_surveys(a_data, **ots)\n",
    "dts_date = dts_date.groupby([\"loc_date\",\"date\"], as_index=False)[unit_label].sum()\n",
    "dts_date[\"date\"] = pd.to_datetime(dts_date[\"date\"]).dt.tz_localize('UTC')   \n",
    "\n",
    "# scale the chart as needed to accomodate for extreme values\n",
    "y_lim = 95\n",
    "y_limit = np.percentile(dts_date[unit_label], y_lim)\n",
    "\n",
    "# label for the chart that alerts to the scale\n",
    "not_included = F\"Werte grösser als {thousandsSeparator(int(round(y_limit,0)), language)} {unit_label} werden nicht gezeigt.\"\n",
    "\n",
    "chart_notes = f\"\"\"\n",
    "*__Links:__ {this_feature[\"name\"]}, {dateToYearAndMonth(datetime.strptime(start_date, date_format), lang=date_lang)} bis {dateToYearAndMonth(datetime.strptime(end_date, date_format), lang=date_lang)}, n = {a_summary[\"loc_date\"]}. {not_included} __Rechts:__ empirische Verteilungsfunktion im {this_feature[\"name\"]}.*\n",
    "\"\"\"\n",
    "\n",
    "# months locator, can be confusing\n",
    "# https://matplotlib.org/stable/api/dates_api.html\n",
    "months = mdates.MonthLocator(interval=1)\n",
    "months_fmt = mdates.DateFormatter(\"%b\")\n",
    "days = mdates.DayLocator(interval=7)\n",
    "\n",
    "# get the monthly or quarterly results for the feature\n",
    "rsmp = fd_dindex.set_index(\"date\")\n",
    "resample_plot, rate = sut.quarterly_or_monthly_values(rsmp, this_feature[\"name\"], vals=unit_label, quarterly=[\"ticino\"])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "# feature surveys\n",
    "sns.scatterplot(data=dts_date, x=dts_date[\"date\"], y=unit_label, label=top, color=\"black\", alpha=0.4,  ax=ax)\n",
    "# all other surveys\n",
    "sns.scatterplot(data=fd_dindex, x=fd_dindex[\"date\"], y=unit_label, label=this_feature[\"name\"], color=\"red\", s=34, ec=\"white\", ax=ax)\n",
    "# monthly or quaterly plot\n",
    "sns.lineplot(data=resample_plot, x=resample_plot.index, y=resample_plot, label=F\"{this_feature['name']}: monatlicher Medianwert\", color=\"magenta\", ax=ax)\n",
    "\n",
    "ax.set_ylim(0,y_limit )\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.xaxis.set_minor_locator(days)\n",
    "ax.xaxis.set_major_formatter(months_fmt)\n",
    "ax.legend()\n",
    "\n",
    "# the cumlative distributions:\n",
    "axtwo = axs[1]\n",
    "\n",
    "# the feature of interest\n",
    "feature_ecd = ECDF(dt_all[unit_label].values)    \n",
    "sns.lineplot(x=feature_ecd.x, y=feature_ecd.y, color=\"darkblue\", ax=axtwo, label=this_feature[\"name\"])\n",
    "\n",
    "# the other features\n",
    "other_features = ECDF(dts_date[unit_label].values)\n",
    "sns.lineplot(x=other_features.x, y=other_features.y, color=\"magenta\", label=top, linewidth=1, ax=axtwo)\n",
    "\n",
    "axtwo.set_xlabel(unit_label, **ck.xlab_k14)\n",
    "axtwo.set_ylabel(\"Verhältnis der Erhebungen\", **ck.xlab_k14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "glue('aare_survey_area_sample_totals', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_sample_totals\n",
    "---\n",
    "name: 'aare_survey_area_sample_totals'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_sample_totals>` __Links:__ Erhebungsgebiet Aare, März 2020 bis Mai 2021, n = 140. Werte grösser als 1 766 p/100 m werden nicht gezeigt. __Rechts:__ empirische Verteilungsfunktion im Erhebungsgebiet Aare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammengefasste Daten und Materialarten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# figure caption\n",
    "summary_of_survey_totals = f\"\"\"\n",
    "*__Links:__ Zusammenfassung der Daten aller Erhebungen {this_feature[\"name\"]}. __Rechts:__ Gefundene Materialarten im {this_feature[\"name\"]} in Stückzahlen und als prozentuale Anteile (stückzahlbezogen).*\n",
    "\"\"\"\n",
    "\n",
    "# get the basic statistics from pd.describe\n",
    "cs = dt_all[unit_label].describe().round(2)\n",
    "\n",
    "# change the names\n",
    "csx = sut.change_series_index_labels(cs, sut.create_summary_table_index(unit_label, lang=\"DE\"))\n",
    "\n",
    "combined_summary =[(x, thousandsSeparator(int(csx[x]), language)) for x in csx.index]\n",
    "\n",
    "agg_pcs_median = {unit_label:\"median\", \"quantity\":\"sum\"}\n",
    "\n",
    "# cumulative statistics for each code\n",
    "code_totals = sut.the_aggregated_object_values(\n",
    "    fd,\n",
    "    agg=agg_pcs_median,\n",
    "    description_map=code_description_map, \n",
    "    material_map=code_material_map\n",
    ")\n",
    "\n",
    "# the materials table\n",
    "fd_mat_totals = sut.the_ratio_object_to_total(code_totals)\n",
    "fd_mat_totals = sut.fmt_pct_of_total(fd_mat_totals)\n",
    "\n",
    "# applly new column names for printing\n",
    "cols_to_use = {\"material\":\"Material\",\"quantity\":\"Gesamt\", \"% of total\":\"% Gesamt\"}\n",
    "fd_mat_t = fd_mat_totals[cols_to_use.keys()].values\n",
    "fd_mat_t = [(x[0], thousandsSeparator(int(x[1]), language), x[2]) for x in fd_mat_t]\n",
    "\n",
    "# make tables\n",
    "fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# summary table\n",
    "# names for the table columns\n",
    "a_col = [this_feature[\"name\"], \"total\"]\n",
    "\n",
    "axone = axs[0]\n",
    "sut.hide_spines_ticks_grids(axone)\n",
    "\n",
    "table_two = sut.make_a_table(axone, combined_summary,  colLabels=a_col, colWidths=[.5,.25,.25],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_two.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_two.set_fontsize(12)\n",
    "\n",
    "# material table\n",
    "axtwo = axs[1]\n",
    "axtwo.set_xlabel(\" \")\n",
    "sut.hide_spines_ticks_grids(axtwo)\n",
    "\n",
    "table_three = sut.make_a_table(axtwo, fd_mat_t,  colLabels=list(cols_to_use.values()), colWidths=[.4, .3,.3],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_three.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "glue('aare_survey_area_sample_material_tables', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`Abbildung %s: <aare_survey_area_sample_material_tables>` __Links__: Zusammenfassung der Daten aller Erhebungen Erhebungsgebiet Aare. __Rechts:__ Gefundene Materialarten im Erhebungsgebiet Aare in Stückzahlen und als prozentuale Anteile (stückzahlbezogen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_sample_material_tables\n",
    "---\n",
    "name: 'aare_survey_area_sample_material_tables'\n",
    "---\n",
    "` `\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die am häufigsten gefundenen Objekte\n",
    "\n",
    "Die am häufigsten gefundenen Objekte sind die zehn mengenmässig am meisten vorkommenden Objekte und/oder Objekte, die in mindestens 50 % aller Datenerhebungen identifiziert wurden (Häufigkeitsrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the top ten by quantity\n",
    "most_abundant = code_totals.sort_values(by=\"quantity\", ascending=False)[:10]\n",
    "\n",
    "# the most common\n",
    "most_common = code_totals[code_totals[\"fail rate\"] >= a_fail_rate].sort_values(by=\"quantity\", ascending=False)\n",
    "\n",
    "# merge with most_common and drop duplicates\n",
    "m_common = pd.concat([most_abundant, most_common]).drop_duplicates()\n",
    "\n",
    "# get percent of total\n",
    "m_common_percent_of_total = m_common.quantity.sum()/code_totals.quantity.sum()\n",
    "\n",
    "rb_string = f\"\"\"\n",
    "*__Unten__: Häufigste Objekte im {this_feature['name']}: d. h. Objekte mit einer Häufigkeitsrate von mindestens 50 % und/oder Top Ten nach Anzahl. Zusammengenommen machen die häufigsten Objekte {int(m_common_percent_of_total*100)}% aller gefundenen Objekte aus. Anmerkung: p/100 m = Medianwert der Erhebung.*\n",
    "\"\"\"\n",
    "md(rb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# format values for table\n",
    "m_common[\"item\"] = m_common.index.map(lambda x: code_description_map.loc[x])\n",
    "m_common[\"% of total\"] = m_common[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "m_common[\"quantity\"] = m_common.quantity.map(lambda x:thousandsSeparator(x, language))\n",
    "m_common[\"fail rate\"] = m_common[\"fail rate\"].map(lambda x: F\"{x}%\")\n",
    "m_common[unit_label] = m_common[unit_label].map(lambda x: F\"{round(x,1)}\")\n",
    "\n",
    "# table header rows\n",
    "cols_to_use = {\"item\":\"Objekt\",\"quantity\":\"Gesamt\", \"% of total\":\"% Gesamt\", \"fail rate\":\"fail-rate\", unit_label:unit_label}\n",
    "\n",
    "most_common_table = m_common[cols_to_use.keys()].values\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(11,len(m_common)*.7))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_four = sut.make_a_table(axs, most_common_table,  colLabels=list(cols_to_use.values()), colWidths=[.52, .12,.12,.12, .12],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_four.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_four.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "glue('aare_survey_area_most_common_tables', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_most_common_tables\n",
    "---\n",
    "name: 'aare_survey_area_most_common_tables'\n",
    "---\n",
    "` `\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die am häufigsten gefundenen Objekte nach Gewässer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "rb_string = F\"\"\"\n",
    "*__Unten:__ Median (p/100 m) der häufigsten Objekte im {this_feature[\"name\"]}.*\n",
    "\"\"\"\n",
    "# md(rb_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# aggregated survey totals for the most common codes for all the water features\n",
    "m_common_st = fd[fd.code.isin(m_common.index)].groupby([this_level, \"loc_date\",\"code\"], as_index=False).agg(agg_pcs_quantity)\n",
    "m_common_ft = m_common_st.groupby([this_level, \"code\"], as_index=False)[unit_label].median()\n",
    "\n",
    "# proper name of water feature for display\n",
    "m_common_ft[\"f_name\"] = m_common_ft[this_level].map(lambda x: comp_labels[x])\n",
    "\n",
    "# map the desctiption to the code\n",
    "m_common_ft[\"item\"] = m_common_ft.code.map(lambda x: code_description_map.loc[x])\n",
    "\n",
    "# pivot that\n",
    "m_c_p = m_common_ft[[\"item\", unit_label, \"f_name\"]].pivot(columns=\"f_name\", index=\"item\")\n",
    "\n",
    "# quash the hierarchal column index\n",
    "m_c_p.columns = m_c_p.columns.get_level_values(1)\n",
    "\n",
    "# the aggregated totals for the survey area\n",
    "c = sut.aggregate_to_group_name(fd[fd.code.isin(m_common.index)], column=\"code\", name=this_feature[\"name\"], val=\"med\", unit_label=unit_label)\n",
    "\n",
    "m_c_p[this_feature[\"name\"]]= sut.change_series_index_labels(c, {x:code_description_map.loc[x] for x in c.index})\n",
    "\n",
    "# the aggregated totals of all the data\n",
    "c = sut.aggregate_to_group_name(a_data[(a_data.code.isin(m_common.index))], column=\"code\", name=top, val=\"med\", unit_label=unit_label)\n",
    "m_c_p[top] = sut.change_series_index_labels(c, {x:code_description_map.loc[x] for x in c.index})\n",
    "\n",
    "# chart that\n",
    "fig, ax  = plt.subplots(figsize=(len(m_c_p.columns)*.9,len(m_c_p)*.9))\n",
    "axone = ax\n",
    "\n",
    "sns.heatmap(m_c_p, ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, fmt=\".1f\", square=True, cbar=False, linewidth=.1, linecolor=\"white\")\n",
    "axone.set_xlabel(\"\")\n",
    "axone.set_ylabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"x\")\n",
    "axone.tick_params(labelsize=12, which=\"both\", axis=\"y\")\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90)\n",
    "\n",
    "glue('aare_survey_area_most_common_heat_map', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`Abbildung %s: <aare_survey_area_most_common_heat_map>` Median (p/100 m) der häufigsten Objekte im Erhebungsgebiet Aare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_most_common_heat_map\n",
    "---\n",
    "name: 'aare_survey_area_most_common_heat_map'\n",
    "---\n",
    "` `\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Die am häufigsten gefundenen Objekte im monatlichen Durchschnitt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "monthly_mc = F\"\"\"\n",
    "*__Below:__ {this_feature[\"name\"]}, monatliche Durchschnittsergebnisse p/100 m.*\n",
    "\"\"\"\n",
    "# md(monthly_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# collect the survey results of the most common objects\n",
    "m_common_m = fd[(fd.code.isin(m_common.index))].groupby([\"loc_date\",\"date\",\"code\", \"groupname\"], as_index=False).agg(agg_pcs_quantity)\n",
    "m_common_m.set_index(\"date\", inplace=True)\n",
    "\n",
    "# set the order of the chart, group the codes by groupname columns\n",
    "an_order = m_common_m.groupby([\"code\",\"groupname\"], as_index=False).quantity.sum().sort_values(by=\"groupname\")[\"code\"].values\n",
    "\n",
    "# a manager dict for the monthly results of each code\n",
    "mgr = {}\n",
    "\n",
    "# get the monhtly results for each code:\n",
    "for a_group in an_order:\n",
    "    # resample by month\n",
    "    a_plot = m_common_m[(m_common_m.code==a_group)][unit_label].resample(\"M\").mean().fillna(0)\n",
    "    this_group = {a_group:a_plot}\n",
    "    mgr.update(this_group)\n",
    "\n",
    "months={\n",
    "    0:\"Jan\",\n",
    "    1:\"Feb\",\n",
    "    2:\"Mar\",\n",
    "    3:\"Apr\",\n",
    "    4:\"May\",\n",
    "    5:\"Jun\",\n",
    "    6:\"Jul\",\n",
    "    7:\"Aug\",\n",
    "    8:\"Sep\",\n",
    "    9:\"Oct\",\n",
    "    10:\"Nov\",\n",
    "    11:\"Dec\"\n",
    "}\n",
    "\n",
    "# convenience function to lable x axis\n",
    "def new_month(x):\n",
    "    if x <= 11:\n",
    "        this_month = x\n",
    "    else:\n",
    "        this_month=x-12    \n",
    "    return this_month\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# define a bottom\n",
    "bottom = [0]*len(mgr[\"G27\"])\n",
    "\n",
    "# the monhtly survey average for all objects and locations\n",
    "# makes the backdrop of the barchart\n",
    "monthly_fd = fd.groupby([\"loc_date\", \"date\"], as_index=False).agg(agg_pcs_quantity)\n",
    "monthly_fd.set_index(\"date\", inplace=True)\n",
    "m_fd = monthly_fd[unit_label].resample(\"M\").mean().fillna(0)\n",
    "\n",
    "# define the xaxis\n",
    "this_x = [i for i,x in  enumerate(m_fd.index)]\n",
    "\n",
    "# plot the monthly total survey average\n",
    "ax.bar(this_x, m_fd.to_numpy(), color=table_row, alpha=0.2, linewidth=1, edgecolor=\"teal\", width=1, label=\"Monatsdurschnitt\") \n",
    "\n",
    "# plot the monthly survey average of the most common objects\n",
    "for i, a_group in enumerate(an_order): \n",
    "    \n",
    "    # define the axis\n",
    "    this_x = [i for i,x in  enumerate(mgr[a_group].index)]\n",
    "    \n",
    "    # collect the month\n",
    "    this_month = [x.month for i,x in enumerate(mgr[a_group].index)]\n",
    "    \n",
    "    # if i == 0 laydown the first bars\n",
    "    if i == 0:\n",
    "        ax.bar(this_x, mgr[a_group].to_numpy(), label=a_group, color=colors_palette[a_group], linewidth=1, alpha=0.6 ) \n",
    "    # else use the previous results to define the bottom\n",
    "    else:\n",
    "        bottom += mgr[an_order[i-1]].to_numpy()        \n",
    "        ax.bar(this_x, mgr[a_group].to_numpy(), bottom=bottom, label=a_group, color=colors_palette[a_group], linewidth=1, alpha=0.8)\n",
    "        \n",
    "# collect the handles and labels from the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# set the location of the x ticks\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i for i in np.arange(len(this_x))]))\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "# label the xticks by month\n",
    "axisticks = ax.get_xticks()\n",
    "labelsx = [sut.months_de[new_month(x-1)] for x in  this_month]\n",
    "plt.xticks(ticks=axisticks, labels=labelsx)\n",
    "\n",
    "# make the legend\n",
    "# swap out codes for descriptions\n",
    "new_labels = [code_description_map.loc[x] for x in labels[1:]]\n",
    "new_labels = new_labels[::-1]\n",
    "\n",
    "# insert a label for the monthly average\n",
    "new_labels.insert(0,\"Monatsdurschnitt\")\n",
    "handles = [handles[0], *handles[1:][::-1]]\n",
    "    \n",
    "plt.legend(handles=handles, labels=new_labels, bbox_to_anchor=(.5, -.05), loc=\"upper center\",  ncol=1, fontsize=14)\n",
    "\n",
    "glue('aare_survey_area_monthly_results', fig, display=False)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`Abbildung %s: <aare_survey_area_monthly_results>` Erhebungsgebiet Aare, monatliche Durchschnittsergebnisse p/100 m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_monthly_results\n",
    "---\n",
    "name: 'aare_survey_area_monthly_results'\n",
    "---\n",
    "` `\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erhebungsergebnisse und Landnutzung\n",
    "\n",
    "Das Landnutzungsprofil ist eine Darstellung der Art und des Umfangs der wirtschaftlichen Aktivität und der Umweltbedingungen rund um den Erhebungsort. Die Schlüsselindikatoren aus den Ergebnissen der Datenerhebungen werden mit dem Landnutzungsprofil für einen Radius von 1500 m um den Erhebungsort verglichen.\n",
    "\n",
    "Eine Assoziation ist eine Beziehung zwischen den Ergebnissen der Datenerhebungen und dem Landnutzungsprofil, die nicht auf Zufall beruht. Das Ausmass der Beziehung ist weder definiert noch linear.\n",
    "\n",
    "Die Rangkorrelation ist ein nicht-parametrischer Test, um festzustellen, ob ein statistisch signifikanter Zusammenhang zwischen der Landnutzung und den bei einer Abfallobjekte-Erhebung identifizierten Objekten besteht.\n",
    "\n",
    "Die verwendete Methode ist der Spearmans Rho oder Spearmans geordneter Korrelationskoeffizient. Die Testergebnisse werden bei p < 0,05 für alle gültigen Erhebungen an Seen im Untersuchungsgebiet ausgewertet.\n",
    "\n",
    "1. Rot/Rosa steht für eine positive Assoziation\n",
    "2. Gelb steht für eine negative Assoziation\n",
    "3. Weiss bedeutet, dass keine statistische Grundlage für die Annahme eines Zusammenhangs besteht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "corr_data = fd[(fd.code.isin(m_common.index))&(fd.water_name_slug.isin(lakes_of_interest))].copy()\n",
    "\n",
    "alert_less_than_100 = len(corr_data.loc_date.unique()) <= 100\n",
    "\n",
    "if alert_less_than_100:\n",
    "    warning = F\"\"\"**There are less than 100 samples, proceed with caution. Beach litter surveys have alot of variance**\"\"\"\n",
    "else:\n",
    "    warning = \"\"\n",
    "\n",
    "association = f\"\"\"\n",
    "\n",
    "*__Unten:__ Ausgewertete Korrelationen der am häufigsten gefundenen Objekte in Bezug auf das Landnutzungsprofil im {this_feature[\"name\"]}. Für alle gültigen Erhebungen an Seen n = {len(corr_data.loc_date.unique())}.*\n",
    "\n",
    "{warning}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# md(association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# chart the results of test for association\n",
    "fig, axs = plt.subplots(len(m_common.index),len(land_use_columns), figsize=(len(land_use_columns)+7,len(m_common.index)+1), sharey=\"row\")\n",
    "\n",
    "# the test is conducted on the survey results for each code\n",
    "for i,code in enumerate(m_common.index):\n",
    "    # slice the data\n",
    "    data = corr_data[corr_data.code == code]\n",
    "    \n",
    "    # run the test on for each land use feature\n",
    "    for j, n in enumerate(land_use_columns):       \n",
    "        # assign ax and set some parameters\n",
    "        ax=axs[i, j]\n",
    "        ax.grid(False)\n",
    "        ax.tick_params(axis=\"both\", which=\"both\",bottom=False,top=False,labelbottom=False, labelleft=False, left=False)\n",
    "        \n",
    "        # check the axis and set titles and labels       \n",
    "        if i == 0:\n",
    "            ax.set_title(F\"{n}\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.set_ylabel(F\"{code_description_map[code]}\", rotation=0, ha=\"right\", **ck.xlab_k14)\n",
    "            ax.set_xlabel(\" \")\n",
    "        else:\n",
    "            ax.set_xlabel(\" \")\n",
    "            ax.set_ylabel(\" \")\n",
    "        # run test\n",
    "        _, corr, a_p = sut.make_plot_with_spearmans(data, ax, n, unit_label=unit_label)\n",
    "        \n",
    "        # if siginficant set adjust color to direction\n",
    "        if a_p < 0.05:\n",
    "            if corr > 0:\n",
    "                ax.patch.set_facecolor(\"salmon\")\n",
    "                ax.patch.set_alpha(0.5)\n",
    "            else:\n",
    "                ax.patch.set_facecolor(\"palegoldenrod\")\n",
    "                ax.patch.set_alpha(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "glue('aare_survey_area_spearmans', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_spearmans\n",
    "---\n",
    "name: 'aare_survey_area_spearmans'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_spearmans>` Ausgewertete Korrelationen der am häufigsten gefundenen Objekte in Bezug auf das Landnutzungsprofil im Erhebungsgebiet Aare. Für alle gültigen Erhebungen an Seen n = 118. *__Legende:__ wenn p > 0,05 = weiss, wenn p < 0,05 und Rho > 0 = rot, wenn p < 0,05 und Rho < 0 = gelb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Verwendungszweck der gefundenen Objekte\n",
    "\n",
    "Der Verwendungszweck basiert auf der Verwendung des Objekts, bevor es weggeworfen wurde, oder auf der Artikelbeschreibung, wenn die ursprüngliche Verwendung unbestimmt ist. Identifizierte Objekte werden einer der 260 vordefinierten Kategorien zugeordnet. Die Kategorien werden je nach Verwendung oder Artikelbeschreibung gruppiert.\n",
    "\n",
    "* Abwasser: Objekte, die aus Kläranlagen freigesetzt werden, sprich Objekte, die wahrscheinlich über die Toilette entsorgt werden\n",
    "* Mikroplastik (< 5 mm): fragmentierte Kunststoffe und Kunststoffharze aus der Vorproduktion\n",
    "* Infrastruktur: Artikel im Zusammenhang mit dem Bau und der Instandhaltung von Gebäuden, Strassen und der Wasser-/Stromversorgung\n",
    "* Essen und Trinken: alle Materialien, die mit dem Konsum von Essen und Trinken in Zusammenhang stehen\n",
    "* Landwirtschaft: Materialien z. B. für Mulch und Reihenabdeckungen, Gewächshäuser, Bodenbegasung, Ballenverpackungen. Einschliesslich Hartkunststoffe für landwirtschaftliche Zäune, Blumentöpfe usw.\n",
    "* Tabakwaren: hauptsächlich Zigarettenfilter, einschliesslich aller mit dem Rauchen verbundenen Materialien\n",
    "* Freizeit und Erholung: Objekte, die mit Sport und Freizeit zu tun haben, z. B. Angeln, Jagen, Wandern usw.\n",
    "* Verpackungen ausser Lebensmittel und Tabak: Verpackungsmaterial, das nicht lebensmittel- oder tabakbezogen ist\n",
    "* Plastikfragmente: Plastikteile unbestimmter Herkunft oder Verwendung\n",
    "* Persönliche Gegenstände: Accessoires, Hygieneartikel und Kleidung\n",
    "\n",
    "Im Anhang (Kapitel 3.6.3) befindet sich die vollständige Liste der identifizierten Objekte, einschliesslich Beschreibungen und Gruppenklassifizierung. Das Kapitel [16 Codegruppen](codegroups) beschreibt jede Codegruppe im Detail und bietet eine umfassende Liste aller Objekte in einer Gruppe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "cg_poft = F\"\"\"\n",
    "__Unten:__ Verwendungszweck oder Beschreibung der identifizierten Objekte in % der Gesamtzahl nach Gewässer im {this_feature[\"name\"]}. Fragmentierte Objekte, die nicht eindeutig identifiziert werden können, werden weiterhin nach ihrer Grösse klassifiziert.\n",
    "\"\"\"\n",
    "# md(cg_poft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# code groups results aggregated by survey\n",
    "groups = [\"loc_date\",\"groupname\"]\n",
    "cg_t = fd.groupby([this_level,*groups], as_index=False).agg(agg_pcs_quantity)\n",
    "\n",
    "# the total per water feature\n",
    "cg_tq = cg_t.groupby(this_level).quantity.sum()\n",
    "\n",
    "# get the fail rates for each group per survey\n",
    "cg_t[\"fail\"]=False\n",
    "cg_t[\"fail\"] = cg_t.quantity.where(lambda x: x == 0, True)\n",
    "\n",
    "# aggregate all that for each municipality\n",
    "agg_this = {unit_label:\"median\", \"quantity\":\"sum\", \"fail\":\"sum\", \"loc_date\":\"nunique\"} \n",
    "cg_t = cg_t.groupby([this_level, \"groupname\"], as_index=False).agg(agg_this)\n",
    "\n",
    "# assign survey area total to each record\n",
    "for a_feature in cg_tq.index:\n",
    "    cg_t.loc[cg_t[this_level] == a_feature, \"f_total\"] = cg_tq.loc[a_feature]\n",
    "\n",
    "# get the percent of total for each group for each survey area\n",
    "cg_t[\"pt\"] = (cg_t.quantity/cg_t.f_total).round(2)\n",
    "\n",
    "# pivot that\n",
    "data_table = cg_t.pivot(columns=this_level, index=\"groupname\", values=\"pt\")\n",
    "\n",
    "# repeat for the survey area\n",
    "data_table[this_feature['name'] ] = sut.aggregate_to_group_name(fd, unit_label=unit_label, column=\"groupname\", name=this_feature['name'] , val=\"pt\")\n",
    "\n",
    "# repeat for all the data\n",
    "data_table[top] = sut.aggregate_to_group_name(a_data, unit_label=unit_label, column=\"groupname\", name=top, val=\"pt\")\n",
    "\n",
    "data = data_table\n",
    "data.rename(columns={x:wname_wname.loc[x][0] for x in data.columns[:-2]}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axone = ax\n",
    "sns.heatmap(data , ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, cbar=False, fmt=\".0%\", linewidth=.1, square=True, linecolor=\"white\")\n",
    "\n",
    "axone.set_ylabel(\"\")\n",
    "axone.set_xlabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"both\", labeltop=False, labelbottom=True)\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90, fontsize=14)\n",
    "plt.setp(axone.get_yticklabels(), rotation=0, fontsize=14)\n",
    "\n",
    "glue('aare_survey_area_codegroup_percent', fig, display=False)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_codegroup_percent\n",
    "---\n",
    "name: 'aare_survey_area_codegroup_percent'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_codegroup_percent>` Verwendungszweck oder Beschreibung der identifizierten Objekte in % der Gesamtzahl nach Gewässer im Erhebungsgebiet Aare. Fragmentierte Objekte, die nicht eindeutig identifiziert werden können, werden weiterhin nach ihrer Grösse klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "cg_medpcm = F\"\"\"\n",
    "<br></br>\n",
    "*__Unten:__ Verwendungszweck der gefundenen Objekte Median p/100 m im {this_feature[\"name\"]}. Fragmentierte Objekte, die nicht eindeutig identifiziert werden können, werden weiterhin nach ihrer Grösse klassifiziert.*\n",
    "\"\"\"\n",
    "# md(cg_medpcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# median p/50m of all the water features\n",
    "data_table = cg_t.pivot(columns=\"water_name_slug\", index=\"groupname\", values=unit_label)\n",
    "\n",
    "# the survey area columns\n",
    "data_table[this_feature['name'] ] = sut.aggregate_to_group_name(fd, unit_label=unit_label, column=\"groupname\", name=this_feature['name'] , val=\"med\")\n",
    "\n",
    "# column for all the surveys\n",
    "data_table[top] = sut.aggregate_to_group_name(a_data, unit_label=unit_label, column=\"groupname\", name=top, val=\"med\")\n",
    "\n",
    "# merge with data_table\n",
    "data = data_table\n",
    "data.rename(columns={x:wname_wname.loc[x][0] for x in data.columns[:-2]}, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axone = ax\n",
    "sns.heatmap(data , ax=axone, cmap=cmap2, annot=True, annot_kws={\"fontsize\":12}, fmt=\"g\", cbar=False, linewidth=.1, square=True, linecolor=\"white\")\n",
    "\n",
    "axone.set_xlabel(\"\")\n",
    "axone.set_ylabel(\"\")\n",
    "axone.tick_params(labelsize=14, which=\"both\", axis=\"both\", labeltop=False, labelbottom=True)\n",
    "\n",
    "plt.setp(axone.get_xticklabels(), rotation=90, fontsize=14)\n",
    "plt.setp(axone.get_yticklabels(), rotation=0, fontsize=14)\n",
    "glue('aare_survey_area_codegroup_pcsm', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_codegroup_pcsm\n",
    "---\n",
    "name: 'aare_survey_area_codegroup_pcsm'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_codegroup_pcsm>` Verwendungszweck der gefundenen Objekte Median p/100 m im Erhebungsgebiet Aare. Fragmentierte Objekte, die nicht eindeutig identifiziert werden können, werden weiterhin nach ihrer Grösse klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fliessgewässer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "rivers = fd[fd.w_t == \"r\"].copy()\n",
    "r_smps = rivers.groupby([\"loc_date\", \"date\", \"location\", \"water_name_slug\"], as_index=False).agg(agg_pcs_quantity)\n",
    "l_smps = fd[fd.w_t == \"l\"].groupby([\"loc_date\",\"date\",\"location\", \"water_name_slug\"], as_index=False).agg(agg_pcs_quantity)\n",
    "\n",
    "chart_notes = F\"\"\"\n",
    "*__Left:__ {this_feature[\"name\"]} Fliessgewässer, {dateToYearAndMonth(datetime.strptime(start_date, date_format), lang=date_lang)} bis {dateToYearAndMonth(datetime.strptime(end_date, date_format), lang=date_lang)}, n = {len(r_smps.loc_date.unique())}. {not_included} __Rechts:__ Zusammenfassung der Daten.*\n",
    "\"\"\"\n",
    "# md(chart_notes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cs = r_smps[unit_label].describe().round(2)\n",
    "\n",
    "# add project totals\n",
    "cs[\"total objects\"] = r_smps.quantity.sum()\n",
    "\n",
    "# change the names\n",
    "csx = sut.change_series_index_labels(cs, sut.create_summary_table_index(unit_label, lang=\"DE\"))\n",
    "\n",
    "combined_summary = sut.fmt_combined_summary(csx, nf=[])\n",
    "\n",
    "# make the charts\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "\n",
    "aspec = fig.add_gridspec(ncols=11, nrows=3)\n",
    "\n",
    "ax = fig.add_subplot(aspec[:, :6])\n",
    "\n",
    "line_label = F\"{rate} median:{top}\"\n",
    "\n",
    "sns.scatterplot(data=l_smps, x=\"date\", y=unit_label, color=\"black\", alpha=0.4, label=\"Lake surveys\", ax=ax)\n",
    "sns.scatterplot(data=r_smps, x=\"date\", y=unit_label, color=\"red\", s=34, ec=\"white\",label=\"River surveys\", ax=ax)\n",
    "\n",
    "ax.set_ylim(-10,y_limit )\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(unit_label, **ck.xlab_k14)\n",
    "\n",
    "ax.xaxis.set_minor_locator(days)\n",
    "ax.xaxis.set_major_formatter(months_fmt)\n",
    "\n",
    "a_col = [this_feature[\"name\"], \"total\"]\n",
    "\n",
    "axone = fig.add_subplot(aspec[:, 7:])\n",
    "sut.hide_spines_ticks_grids(axone)\n",
    "\n",
    "table_five = sut.make_a_table(axone, combined_summary,  colLabels=a_col, colWidths=[.75,.25],  bbox=[0,0,1,1], **{\"loc\":\"lower center\"})\n",
    "table_five.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "glue('aare_survey_area_rivers_summary', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_rivers_summary\n",
    "---\n",
    "name: 'aare_survey_area_rivers_summary'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_rivers_summary>` __Links:__ Erhebungsgebiet Aare Fliessgewässer, März 2020 bis Mai 2021, n = 22. Werte grösser als 1 766 p/100 m werden nicht gezeigt. __Rechts:__ Zusammenfassung der Daten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die an Fliessgewässern am häufigsten gefundenen Objekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "riv_mcommon = F\"\"\"\n",
    "*__Below:__ Häufigste Objekte p/100 m an Fliessgewässern im {this_feature[\"name\"]}: Medianwert der Erhebung.*\n",
    "\"\"\"\n",
    "# md(riv_mcommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# the most common items rivers\n",
    "r_codes = rivers.groupby(\"code\").agg({\"quantity\":\"sum\", \"fail\":\"sum\", unit_label:\"median\"})\n",
    "r_codes[\"Fail rate\"] = (r_codes.fail/r_smps.loc_date.nunique()*100).astype(\"int\")\n",
    "\n",
    "# top ten\n",
    "r_byq = r_codes.sort_values(by=\"quantity\", ascending=False)[:10].index\n",
    "\n",
    "# most common\n",
    "r_byfail = r_codes[r_codes[\"Fail rate\"] > 49.99].index\n",
    "r_most_common = list(set(r_byq) | set(r_byfail))\n",
    "\n",
    "# format for display\n",
    "r_mc= r_codes.loc[r_most_common].copy()\n",
    "r_mc[\"item\"] = r_mc.index.map(lambda x: code_description_map.loc[x])\n",
    "r_mc.sort_values(by=\"quantity\", ascending=False, inplace=True)\n",
    "\n",
    "r_mc[\"% of total\"]=((r_mc.quantity/r_codes.quantity.sum())*100).astype(\"int\")\n",
    "r_mc[\"% of total\"] = r_mc[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "r_mc[\"quantity\"] = r_mc.quantity.map(lambda x: \"{:,}\".format(x))\n",
    "r_mc[\"Fail rate\"] = r_mc[\"Fail rate\"].map(lambda x: F\"{x}%\")\n",
    "r_mc[\"p/50m\"] = r_mc[unit_label].map(lambda x: F\"{np.ceil(x)}\")\n",
    "r_mc.rename(columns=cols_to_use, inplace=True)\n",
    "\n",
    "data=r_mc[[\"Objekt\",\"Gesamt\", \"% Gesamt\", \"Fail rate\", unit_label]]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,len(data)*.8))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_six = sut.make_a_table(axs, data.values,  colLabels=list(data.columns), colWidths=[.48, .13,.13,.13, .13], **{\"loc\":\"lower center\"})\n",
    "table_six.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "glue('aare_survey_area_rivers_most_common', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_rivers_most_common\n",
    "---\n",
    "name: 'aare_survey_area_rivers_most_common'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_rivers_most_common>` Häufigste Objekte p/100 m an Fliessgewässern im Erhebungsgebiet Aare: Medianwert der Erhebung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang\n",
    "\n",
    "### Schaumstoffe und Kunststoffe nach Grösse\n",
    "\n",
    "Die folgende Tabelle enthält die Komponenten «Gfoam» und «Gfrag», die für die Analyse gruppiert wurden. Objekte, die als Schaumstoffe gekennzeichnet sind, werden als Gfoam gruppiert und umfassen alle geschäumten Polystyrol-Kunststoffe > 0,5 cm. Kunststoffteile und Objekte aus kombinierten Kunststoff- und Schaumstoffmaterialien > 0,5 cm werden für die Analyse als Gfrags gruppiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "frag_foams = F\"\"\"\n",
    "*__Below:__ Fragmentierte und geschäumte Kunststoffe nach Grösse im {this_feature[\"name\"]},  Median p/100 m, Anzahl der gefundenen Objekte und Prozent der Gesamtmenge.*\n",
    "\"\"\"\n",
    "# md(frag_foams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# collect the data before aggregating foams for all locations in the survye area\n",
    "# group by loc_date and code\n",
    "# Combine the different sizes of fragmented plastics and styrofoam\n",
    "# the codes for the foams\n",
    "before_agg = pd.read_csv(\"resources/checked_before_agg_sdata_eos_2020_21.csv\")\n",
    "some_foams = [\"G81\", \"G82\", \"G83\", \"G74\"]\n",
    "before_agg.rename(columns={\"p/100m\":unit_label}, inplace=True)\n",
    "\n",
    "# the codes for the fragmented plastics\n",
    "some_frag_plas = list(before_agg[before_agg.groupname == \"plastic pieces\"].code.unique())\n",
    "\n",
    "fd_frags_foams = before_agg[(before_agg.code.isin([*some_frag_plas, *some_foams]))&(before_agg.location.isin(a_summary[\"locations_of_interest\"]))].groupby([\"loc_date\",\"code\"], as_index=False).agg(agg_pcs_quantity)\n",
    "fd_frags_foams = fd_frags_foams.groupby(\"code\").agg(agg_pcs_median)\n",
    "\n",
    "# add code description and format for printing\n",
    "fd_frags_foams[\"item\"] = fd_frags_foams.index.map(lambda x: code_description_map.loc[x])\n",
    "fd_frags_foams[\"% of total\"] = (fd_frags_foams.quantity/fd.quantity.sum()*100).round(2)\n",
    "fd_frags_foams[\"% of total\"] = fd_frags_foams[\"% of total\"].map(lambda x: F\"{x}%\")\n",
    "fd_frags_foams[\"quantity\"] = fd_frags_foams[\"quantity\"].map(lambda x: F\"{x:,}\")\n",
    "\n",
    "# table data\n",
    "data = fd_frags_foams[[\"item\",unit_label, \"quantity\", \"% of total\"]]\n",
    "data.rename(columns={\"quantity\":\"Gesamt\", \"% of total\":\"% Gesamt\"}, inplace=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(len(data.columns)*2.4,len(data)*.7))\n",
    "\n",
    "sut.hide_spines_ticks_grids(axs)\n",
    "\n",
    "table_seven = sut.make_a_table(axs,data.values,  colLabels=data.columns, colWidths=[.6, .13, .13, .13], a_color=table_row)\n",
    "table_seven.get_celld()[(0,0)].get_text().set_text(\" \")\n",
    "table_seven.set_fontsize(12)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "glue('aare_survey_area_fragmented_plastics', fig, display=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} aare_survey_area_fragmented_plastics\n",
    "---\n",
    "name: 'aare_survey_area_fragmented_plastics'\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`Abbildung %s: <aare_survey_area_fragmented_plastics>`  Fragmentierte und geschäumte Kunststoffe nach Grösse im Erhebungsgebiet Aare, Median p/100 m, Anzahl der gefundenen Objekte und Prozent der Gesamtmenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Erhebungsorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# display the survey locations\n",
    "disp_columns = [\"latitude\", \"longitude\", \"city\"]\n",
    "disp_beaches = dfBeaches.loc[a_summary[\"locations_of_interest\"]][disp_columns]\n",
    "disp_beaches.reset_index(inplace=True)\n",
    "disp_beaches.rename(columns={\"city\":\"stat\", \"slug\":\"standort\"}, inplace=True)\n",
    "disp_beaches.set_index(\"standort\", inplace=True, drop=True)\n",
    "\n",
    "disp_beaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inventar der Objekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "complete_inventory = code_totals[code_totals.quantity>0][[\"item\", \"groupname\", \"quantity\", \"% of total\",\"fail rate\"]]\n",
    "complete_inventory.rename(columns={\"item\":\"Objekte\", \"groupname\":\"Gruppenname\", \"quantity\":\"Gesamt\", \"% of total\":\"% Gesamt\", \"fail rate\":\"fail rate\" }, inplace=True)\n",
    "\n",
    "\n",
    "complete_inventory.sort_values(by=\"Gesamt\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
