{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a2fc6d-c7f0-412c-9206-c80f9662c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codes init called\n",
      "this is german\n",
      "making material and description map\n",
      "making feature data\n",
      "There are columns\n",
      "renaming columns\n",
      "sample totals\n",
      "making daily total summary\n",
      "making the code summary first\n",
      "making material summary\n",
      "getting the fail rate\n",
      "making most common codes table\n",
      "Codes init called\n",
      "making feature data\n",
      "There are columns\n",
      "renaming columns\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# This is a report using the data from IQAASL.\n",
    "# IQAASL was a project funded by the Swiss Confederation\n",
    "# It produces a summary of litter survey results for a defined region.\n",
    "# These charts serve as the models for the development of plagespropres.ch\n",
    "# The data is gathered by volunteers.\n",
    "# Please remember all copyrights apply, please give credit when applicable\n",
    "# The repo is maintained by the community effective January 01, 2022\n",
    "# There is ample opportunity to contribute, learn and teach\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# Dies ist ein Bericht, der die Daten von IQAASL verwendet.\n",
    "# IQAASL war ein von der Schweizerischen Eidgenossenschaft finanziertes Projekt.\n",
    "# Es erstellt eine Zusammenfassung der Ergebnisse der Littering-Umfrage für eine bestimmte Region.\n",
    "# Diese Grafiken dienten als Vorlage für die Entwicklung von plagespropres.ch.\n",
    "# Die Daten werden von Freiwilligen gesammelt.\n",
    "# Bitte denken Sie daran, dass alle Copyrights gelten, bitte geben Sie den Namen an, wenn zutreffend.\n",
    "# Das Repo wird ab dem 01. Januar 2022 von der Community gepflegt.\n",
    "# Es gibt reichlich Gelegenheit, etwas beizutragen, zu lernen und zu lehren.\n",
    "# Kontakt dev@hammerdirt.ch\n",
    "\n",
    "# Il s'agit d'un rapport utilisant les données de IQAASL.\n",
    "# IQAASL était un projet financé par la Confédération suisse.\n",
    "# Il produit un résumé des résultats de l'enquête sur les déchets sauvages pour une région définie.\n",
    "# Ces tableaux ont servi de modèles pour le développement de plagespropres.ch\n",
    "# Les données sont recueillies par des bénévoles.\n",
    "# N'oubliez pas que tous les droits d'auteur s'appliquent, veuillez indiquer le crédit lorsque cela est possible.\n",
    "# Le dépôt est maintenu par la communauté à partir du 1er janvier 2022.\n",
    "# Il y a de nombreuses possibilités de contribuer, d'apprendre et d'enseigner.\n",
    "# contact dev@hammerdirt.ch\n",
    "\n",
    "# sys, file and nav packages:\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, time\n",
    "from babel.dates import format_date, format_datetime, format_time, get_month_names\n",
    "import locale\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from math import pi\n",
    "\n",
    "# charting:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import BasicTicker, ColorBar, LinearColorMapper, PrintfTickFormatter\n",
    "from bokeh.sampledata.unemployment1948 import data\n",
    "\n",
    "# the module that has all the methods for handling the data\n",
    "import resources.featuredata as featuredata\n",
    "\n",
    "# home brew utitilties\n",
    "import resources.chart_kwargs as ck\n",
    "import resources.sr_ut as sut\n",
    "\n",
    "# images and display\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "# chart style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# colors for gradients\n",
    "cmap2 = ck.cmap2\n",
    "colors_palette = ck.colors_palette\n",
    "\n",
    "# border and row shading fro tables\n",
    "a_color = \"saddlebrown\"\n",
    "table_row = \"saddlebrown\"\n",
    "\n",
    "## !! Begin Note book variables !!\n",
    "# There are two language variants: german and english\n",
    "# change both: date_lang and language\n",
    "date_lang =  'de_DE.utf8'\n",
    "locale.setlocale(locale.LC_ALL, date_lang)\n",
    "\n",
    "# the date format of the survey data is defined in the module\n",
    "date_format = featuredata.date_format\n",
    "\n",
    "# the language setting use lower case: en or de\n",
    "# changing the language may require changing the unit label\n",
    "language = \"de\"\n",
    "unit_label = \"p/100 m\"\n",
    "\n",
    "# the standard date format is \"%Y-%m-%d\" if your date column is\n",
    "# not in this format it will not work.\n",
    "# these dates cover the duration of the IQAASL project\n",
    "start_date = \"2020-03-01\"\n",
    "end_date =\"2021-05-31\"\n",
    "start_end = [start_date, end_date]\n",
    "\n",
    "# the fail rate used to calculate the most common codes is\n",
    "# 50% it can be changed:\n",
    "fail_rate = 50\n",
    "\n",
    "# Changing these variables produces different reports\n",
    "# Call the map image for the area of interest\n",
    "bassin_map = \"resources/maps/survey_areas/aare_scaled.jpeg\"\n",
    "\n",
    "# the label for the aggregation of all data in the region\n",
    "top = \"Alle Erhebungsgebiete\"\n",
    "\n",
    "# define the feature level and components\n",
    "# the feature of interest is the Aare (aare) at the river basin (river_bassin) level.\n",
    "# the label for charting is called 'name'\n",
    "this_feature = {'slug':'all', 'name':\"Alle Erhebungsgebiete\", 'level':'all'}\n",
    "\n",
    "# these are the smallest aggregated components\n",
    "# choices are water_name_slug=lake or river, city or location at the scale of a river bassin \n",
    "# water body or lake maybe the most appropriate\n",
    "this_level = 'river_bassin'\n",
    "\n",
    "# identify the lakes of interest for the survey area\n",
    "lakes_of_interest = [\"neuenburgersee\", \"thunersee\", \"bielersee\", \"brienzersee\"]\n",
    "\n",
    "# !! End note book variables !!\n",
    "\n",
    "## data\n",
    "# Survey location details (GPS, city, land use)\n",
    "dfBeaches = pd.read_csv(\"resources/beaches_with_land_use_rates.csv\")\n",
    "# set the index of the beach data to location slug\n",
    "dfBeaches.set_index(\"slug\", inplace=True)\n",
    "\n",
    "# Survey dimensions and weights\n",
    "dfDims = pd.read_csv(\"resources/corrected_dims.csv\")\n",
    "\n",
    "# code definitions\n",
    "dxCodes = pd.read_csv(\"resources/codes_with_group_names\")\n",
    "dxCodes.set_index(\"code\", inplace=True)\n",
    "\n",
    "# columns that need to be renamed. Setting the language will automatically\n",
    "# change column names, code descriptions and chart annotations\n",
    "columns={\"% to agg\":\"% agg\", \"% to recreation\": \"% recreation\", \"% to woods\":\"% woods\", \"% to buildings\":\"% buildings\", \"p/100m\":\"p/100 m\"}\n",
    "\n",
    "# key word arguments to construct feature data\n",
    "# !Note the water type allows the selection of river or lakes\n",
    "# if None then the data is aggregated together. This selection\n",
    "# is only valid for survey-area reports or other aggregated data\n",
    "# that may have survey results from both lakes and rivers.\n",
    "fd_kwargs ={\n",
    "    \"filename\": \"resources/checked_sdata_eos_2020_21.csv\",\n",
    "    \"feature_name\": this_feature['slug'], \n",
    "    \"feature_level\": this_feature['level'], \n",
    "    \"these_features\": this_feature['slug'], \n",
    "    \"component\": this_level, \n",
    "    \"columns\": columns, \n",
    "    \"language\": 'de', \n",
    "    \"unit_label\": unit_label, \n",
    "    \"fail_rate\": fail_rate,\n",
    "    \"code_data\":dxCodes,\n",
    "    \"date_range\": start_end,\n",
    "    \"water_type\": None,    \n",
    "}\n",
    "\n",
    "fdx = featuredata.Components(**fd_kwargs)\n",
    "\n",
    "# call the reports and languages\n",
    "fdx.adjustForLanguage()\n",
    "fdx.makeFeatureData()\n",
    "fdx.locationSampleTotals()\n",
    "fdx.makeDailyTotalSummary()\n",
    "fdx.materialSummary()\n",
    "fdx.mostCommon()\n",
    "# !this is the feature data!\n",
    "fd = fdx.feature_data\n",
    "\n",
    "# the period data is all the data that was collected\n",
    "# during the same period from all the other locations\n",
    "# not included in the feature data for a survey area\n",
    "# or river bassin the parent and feature level are the\n",
    "# the same.\n",
    "period_kwargs = {\n",
    "    \"period_data\": fdx.period_data,\n",
    "    \"these_features\": this_feature['slug'],\n",
    "    \"feature_level\":this_feature['level'],\n",
    "    \"feature_parent\":this_feature['slug'],\n",
    "    \"parent_level\": this_feature['level'],\n",
    "    \"period_name\": top,\n",
    "    \"unit_label\": unit_label,\n",
    "    \"most_common\": fdx.most_common.index\n",
    "}\n",
    "period_data = featuredata.PeriodResults(**period_kwargs)\n",
    "\n",
    "# the rivers are considered separately\n",
    "# select only the results from rivers\n",
    "fd_rivers = fd_kwargs.update({\"water_type\":\"r\"})\n",
    "fdr = featuredata.Components(**fd_kwargs)\n",
    "fdr.makeFeatureData()\n",
    "\n",
    "# collects the summarized values for the feature data\n",
    "# use this to generate the summary data for the survey area\n",
    "# and the section for the rivers\n",
    "admin_details = featuredata.AdministrativeSummary(data=fd, dims_data=dfDims, label=this_feature[\"name\"], feature_component=this_level, date_range=start_end, **{\"dfBeaches\":dfBeaches})\n",
    "admin_r_details = featuredata.AdministrativeSummary(data=fdr.feature_data, dims_data=dfDims, label=this_feature[\"name\"], feature_component=this_level, date_range=start_end, **{\"dfBeaches\":dfBeaches})\n",
    "admin_summary = admin_details.summaryObject()\n",
    "admin_r_summary = admin_r_details.summaryObject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848ec86a-c7af-4ab9-8e6e-e216c5d2e89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Im Zeitraum von März 2020  bis Mai 2021 wurden im Rahmen von 386 Datenerhebungen insgesamt 54 744 Objekte entfernt und identifiziert. Die Ergebnisse des Alle Erhebungsgebiete umfassen 143 Orte, 77 Gemeinden und eine Gesamtbevölkerung von etwa 1 735 991 Einwohnenden.\n",
       "\n",
       "*Seen:*\n",
       "\n",
       ">Bielersee, Brienzersee, Lac Léman, Lago Maggiore, Lago di Lugano, Neuenburgersee, Quatre Cantons, Thunersee, Walensee, Zugersee, Zurichsee\n",
       "\n",
       "*Fliessgewässer:*\n",
       "\n",
       ">Aare, Aare|Nidau-Büren-Kanal, Cassarate, Dorfbach, Emme, Escherkanal, Jona, La Thièle, Limmat, Linthkanal, Maggia, Reuss, Rhône, Schüss, Seez, Sihl, Ticino\n",
       "\n",
       "*Gemeinden:*\n",
       "\n",
       ">Aarau, Allaman, Ascona, Beatenberg, Bellinzona, Bern, Biel/Bienne, Boudry, Bourg-en-Lavaux, Brienz (BE), Brissago, Brugg, Brügg, Burgdorf, Bönigen, Cheyres-Châbles, Cudrefin, Dietikon, Erlach, Estavayer, Freienbach, Gals, Gambarogno, Gebenstorf, Genève, Gland, Glarus Nord, Grandson, Hauterive (NE), Hünenberg, Kallnach, Köniz, Küsnacht (ZH), La Tour-de-Peilz, Lausanne, Lavey-Morcles, Le Landeron, Leuk, Ligerz, Locarno, Lugano, Luterbach, Lüscherz, Merenschwand, Minusio, Montreux, Neuchâtel, Nidau, Port, Préverenges, Quarten, Rapperswil-Jona, Richterswil, Riddes, Rubigen, Saint-Gingolph, Saint-Sulpice (VD), Salgesch, Schmerikon, Sion, Solothurn, Spiez, Stäfa, Thun, Tolochenaz, Unterengstringen, Unterseen, Versoix, Vevey, Vinelz, Walenstadt, Walperswil, Weesen, Weggis, Yverdon-les-Bains, Zug, Zürich\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rivers = admin_details.riversOfInterest()\n",
    "lakes = admin_details.lakesOfInterest()\n",
    "        \n",
    "# string objects for display\n",
    "obj_string = featuredata.thousandsSeparator(admin_summary[\"quantity\"], language)\n",
    "surv_string = \"{:,}\".format(admin_summary[\"loc_date\"])\n",
    "pop_string = featuredata.thousandsSeparator(int(admin_summary[\"population\"]), language)\n",
    "\n",
    "# make strings\n",
    "date_quantity_context = F\"Im Zeitraum von {featuredata.dateToYearAndMonth(datetime.strptime(start_date, date_format), lang=date_lang)}  bis {featuredata.dateToYearAndMonth(datetime.strptime(end_date, date_format), lang= date_lang)} wurden im Rahmen von {surv_string} Datenerhebungen insgesamt {obj_string } Objekte entfernt und identifiziert.\"\n",
    "geo_context = F\"Die Ergebnisse des {this_feature['name']} umfassen {admin_summary['location']} Orte, {admin_summary['city']} Gemeinden und eine Gesamtbevölkerung von etwa {pop_string} Einwohnenden.\"\n",
    "\n",
    "# lists of landmarks of interest\n",
    "munis_joined = \", \".join(sorted(admin_details.populationKeys()[\"city\"]))\n",
    "lakes_joined = \", \".join(sorted(lakes))\n",
    "rivers_joined = \", \".join(sorted(rivers))\n",
    "\n",
    "# put that all together:\n",
    "lake_string = F\"\"\"\n",
    "{date_quantity_context} {geo_context }\n",
    "\n",
    "*Seen:*\\n\\n>{lakes_joined}\n",
    "\n",
    "*Fliessgewässer:*\\n\\n>{rivers_joined}\n",
    "\n",
    "*Gemeinden:*\\n\\n>{munis_joined}\n",
    "\"\"\"\n",
    "md(lake_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff2ddb7-0264-4d5a-b23f-bb5a00e15054",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['all'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m land_use_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: period_data\u001b[38;5;241m.\u001b[39mperiod_data,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_column\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc_date\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m    \n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m project_profile \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturedata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLandUseProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mland_use_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyIndexColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m land_use_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m:fdx\u001b[38;5;241m.\u001b[39mfeature_data})\n\u001b[1;32m     11\u001b[0m feature_profile \u001b[38;5;241m=\u001b[39m featuredata\u001b[38;5;241m.\u001b[39mLandUseProfile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mland_use_kwargs)\u001b[38;5;241m.\u001b[39mfeatureOfInterest()\n",
      "File \u001b[0;32m~/dev/iqaasl/resources/featuredata.py:317\u001b[0m, in \u001b[0;36mLandUseProfile.byIndexColumn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m data \u001b[38;5;241m=\u001b[39m thereIsData(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, atype\u001b[38;5;241m=\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame,))\n\u001b[1;32m    316\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_column, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_level, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mland_use_columns]\n\u001b[0;32m--> 317\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/anaconda3/envs/dscy/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dscy/lib/python3.10/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dscy/lib/python3.10/site-packages/pandas/core/indexes/base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['all'] not in index\""
     ]
    }
   ],
   "source": [
    "land_use_kwargs = {\n",
    "    \"data\": period_data.period_data,\n",
    "    \"index_column\":\"loc_date\",\n",
    "    \"these_features\": this_feature['slug'],\n",
    "    \"feature_level\":this_feature['level'],\n",
    "   \n",
    "}\n",
    "project_profile = featuredata.LandUseProfile(**land_use_kwargs).byIndexColumn()\n",
    "\n",
    "land_use_kwargs.update({\"data\":fdx.feature_data})\n",
    "feature_profile = featuredata.LandUseProfile(**land_use_kwargs).featureOfInterest()\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9,8), sharey=\"row\")\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "for i, n in enumerate(featuredata.default_land_use_columns):\n",
    "    r = i%2\n",
    "    c = i%3\n",
    "    ax=axs[r,c]\n",
    "    \n",
    "    # the value of landuse feature n for the survey area:\n",
    "    data=feature_profile[n].values\n",
    "    xs, ys = featuredata.empiricalCDF(data)   \n",
    "    sns.lineplot(x=xs, y=ys, ax=ax, label=admin_details.label)\n",
    "    \n",
    "    # the value of the land use feature n for all the data\n",
    "    testx, testy = featuredata.empiricalCDF(project_profile[n].values)\n",
    "    sns.lineplot(x=testx, y=testy, ax=ax, label=top, color=\"magenta\")\n",
    "    \n",
    "    # get the median from the data\n",
    "    the_median = np.median(data)\n",
    "    \n",
    "    # plot the median and drop horzontal and vertical lines\n",
    "    ax.scatter([the_median], 0.5, color=\"red\",s=50, linewidth=2, zorder=100, label=\"Median\")\n",
    "    ax.vlines(x=the_median, ymin=0, ymax=0.5, color=\"red\", linewidth=2)\n",
    "    ax.hlines(xmax=the_median, xmin=0, y=0.5, color=\"red\", linewidth=2)\n",
    "    \n",
    "    if i <= 3:\n",
    "        if c == 0:            \n",
    "            ax.set_ylabel(\"Ratio of samples\", **ck.xlab_k)\n",
    "            ax.yaxis.set_major_locator(MultipleLocator(.1))\n",
    "        ax.xaxis.set_major_formatter(ticker.PercentFormatter(1.0, 0, \"%\"))        \n",
    "    else:\n",
    "        pass      \n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()    \n",
    "    ax.set_xlabel(list(featuredata.luse_ge.values())[i], **ck.xlab_k)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9, hspace=.3)\n",
    "plt.suptitle(\"Landnutzung im Umkries von 1 500 m um den Erhebungsort\", ha=\"center\", y=1, fontsize=16)\n",
    "fig.legend(handles, labels, bbox_to_anchor=(.5,.94), loc=\"center\", ncol=3) \n",
    "\n",
    "# glue(\"aare_survey_area_landuse\", fig, display=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95c2aa-f5ae-4b4a-9664-dd85601e44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_data_r = admin_r_details.dimensionalSummary()\n",
    "dims_data = admin_details.dimensionalSummary()\n",
    "\n",
    "combined_dims = pd.concat([dims_data, dims_data_r])\n",
    "# combined_dims.reset_index(drop=False, inplace=True)\n",
    "# combined_dims.groupby('water_name_slug', as_index=False)\n",
    "dims_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1562b-4886-496e-ade6-ec567882493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdx.material_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd85197-4433-403f-8f55-6a3787aafbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdx.sample_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4269f7-a7e1-4167-a0a4-aafd2f14edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdx.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabafd9-098c-4e80-9c90-eae70681a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2dbe67-9a38-401a-95a4-cebf97945226",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = period_data.parentSampleTotals(parent=False)\n",
    "d = fdx.sample_totals\n",
    "\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\")\n",
    "\n",
    "p.circle(dx[\"date\"], dx[\"p/100 m\"], fill_color=\"black\", size=10, line_width=0)\n",
    "p.circle(d[\"date\"], d[\"p/100 m\"], fill_color=\"magenta\", size=10, line_width=0)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2d298-2245-4452-8fe0-e2a2bdd79044",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = fdx.componentMostCommonPcsM()\n",
    "\n",
    "# pivot that\n",
    "mc_comp = components[[\"item\", unit_label, \"river_bassin\"]].pivot(columns=\"river_bassin\", index=\"item\")\n",
    "\n",
    "# quash the hierarchal column index\n",
    "mc_comp.columns = mc_comp.columns.get_level_values(1)\n",
    "\n",
    "# the aggregated totals for the survey area\n",
    "mc_feature = fdx.most_common[unit_label]\n",
    "mc_feature = featuredata.changeSeriesIndexLabels(mc_feature, {x:fdx.dMap.loc[x] for x in mc_feature.index})\n",
    "\n",
    "# the aggregated totals of all the data\n",
    "mc_period = period_data.parentMostCommon(parent=False)\n",
    "mc_period = featuredata.changeSeriesIndexLabels(mc_period, {x:fdx.dMap.loc[x] for x in mc_period.index})\n",
    "\n",
    "mc_comp[this_feature[\"name\"]]= mc_feature\n",
    "mc_comp[top] = mc_period\n",
    "mc_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86275da-20d9-42c2-9f25-8baa7785a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = fdx.componentCodeGroupResults()\n",
    "\n",
    "# pivot that\n",
    "pt_comp = components[[\"river_bassin\", \"groupname\", 'pt' ]].pivot(columns=\"river_bassin\", index=\"groupname\")\n",
    "\n",
    "# quash the hierarchal column index\n",
    "pt_comp.columns = pt_comp.columns.get_level_values(1)\n",
    "\n",
    "# # the aggregated totals for the parent level\n",
    "# pt_parent = period_data.parentGroupTotals(parent=True, percent=True)\n",
    "# pt_comp[this_feature[\"name\"]] = pt_parent\n",
    "\n",
    "# the aggregated totals for the period\n",
    "pt_period = period_data.parentGroupTotals(parent=False, percent=True)\n",
    "pt_comp[top] = pt_period\n",
    "pt_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1b7df-9e07-4abb-ad50-6627956a6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_rivers = fd_kwargs.update({\"water_type\":\"r\"})\n",
    "\n",
    "fdr = featuredata.Components(**fd_kwargs)\n",
    "fdr.adjustForLanguage()\n",
    "fdr.makeFeatureData()\n",
    "fdr.locationSampleTotals()\n",
    "fdr.makeDailyTotalSummary()\n",
    "fdr.materialSummary()\n",
    "fdr.mostCommon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b858d92-2a7d-465b-b014-e235a5f6e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = fdr.sample_totals\n",
    "p = figure(x_axis_type=\"datetime\")\n",
    "\n",
    "p.circle(dr[\"date\"], dr[\"p/100 m\"], fill_color=\"magenta\", size=10, line_width=0)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520775c-67c4-4759-ba26-712ef21f3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr.sample_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514f999-fbcc-4ed1-8dfc-83e149a78efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb4377-f8cc-42b4-9c20-16182a9ec519",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_agg = pd.read_csv(\"resources/checked_before_agg_sdata_eos_2020_21.csv\")\n",
    "some_foams = [\"G81\", \"G82\", \"G83\", \"G74\"]\n",
    "before_agg.rename(columns={\"p/100m\":unit_label}, inplace=True)\n",
    "agg_pcs_median = {unit_label:\"median\", \"quantity\":\"sum\"}\n",
    "agg_pcs_quantity = {unit_label:\"sum\", \"quantity\":\"sum\"}\n",
    "\n",
    "# the codes for the fragmented plastics\n",
    "some_frag_plas = list(before_agg[before_agg.groupname == \"plastic pieces\"].code.unique())\n",
    "mask = ((before_agg.code.isin([*some_frag_plas, *some_foams]))&(before_agg.location.isin(admin_summary[\"locations_of_interest\"])))\n",
    "\n",
    "fd_frags_foams = before_agg[mask].groupby([\"loc_date\",\"code\"], as_index=False).agg(agg_pcs_quantity)\n",
    "fd_frags_foams = fd_frags_foams.groupby(\"code\").agg(agg_pcs_median)\n",
    "fd_frags_foams[\"item\"] = fd_frags_foams.index.map(lambda x: fdx.dMap.loc[x])\n",
    "fd_frags_foams[\"% of total\"] = (fd_frags_foams.quantity/fd.quantity.sum()*100).round(2)\n",
    "fd_frags_foams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb296da-50a0-425b-bc62-b26d262c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.sampledata.periodic_table import elements\n",
    "from bokeh.transform import dodge, factor_cmap\n",
    "\n",
    "periods = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\"]\n",
    "groups = [str(x) for x in range(1, 19)]\n",
    "\n",
    "df = elements.copy()\n",
    "df[\"atomic mass\"] = df[\"atomic mass\"].astype(str)\n",
    "df[\"group\"] = df[\"group\"].astype(str)\n",
    "df[\"period\"] = [periods[x-1] for x in df.period]\n",
    "df = df[df.group != \"-\"]\n",
    "df = df[df.symbol != \"Lr\"]\n",
    "df = df[df.symbol != \"Lu\"]\n",
    "\n",
    "cmap = {\n",
    "    \"alkali metal\"         : \"#a6cee3\",\n",
    "    \"alkaline earth metal\" : \"#1f78b4\",\n",
    "    \"metal\"                : \"#d93b43\",\n",
    "    \"halogen\"              : \"#999d9a\",\n",
    "    \"metalloid\"            : \"#e08d49\",\n",
    "    \"noble gas\"            : \"#eaeaea\",\n",
    "    \"nonmetal\"             : \"#f1d4Af\",\n",
    "    \"transition metal\"     : \"#599d7A\",\n",
    "}\n",
    "\n",
    "TOOLTIPS = [\n",
    "    (\"Name\", \"@name\"),\n",
    "    (\"Atomic number\", \"@{atomic number}\"),\n",
    "    (\"Atomic mass\", \"@{atomic mass}\"),\n",
    "    (\"Type\", \"@metal\"),\n",
    "    (\"CPK color\", \"$color[hex, swatch]:CPK\"),\n",
    "    (\"Electronic configuration\", \"@{electronic configuration}\"),\n",
    "]\n",
    "\n",
    "p = figure(title=\"Periodic Table (omitting LA and AC Series)\", width=1000, height=450,\n",
    "           x_range=groups, y_range=list(reversed(periods)),\n",
    "           tools=\"hover\", toolbar_location=None, tooltips=TOOLTIPS)\n",
    "\n",
    "r = p.rect(\"group\", \"period\", 0.95, 0.95, source=df, fill_alpha=0.6, legend_field=\"metal\",\n",
    "           color=factor_cmap('metal', palette=list(cmap.values()), factors=list(cmap.keys())))\n",
    "\n",
    "text_props = dict(source=df, text_align=\"left\", text_baseline=\"middle\")\n",
    "\n",
    "x = dodge(\"group\", -0.4, range=p.x_range)\n",
    "\n",
    "p.text(x=x, y=\"period\", text=\"symbol\", text_font_style=\"bold\", **text_props)\n",
    "\n",
    "p.text(x=x, y=dodge(\"period\", 0.3, range=p.y_range), text=\"atomic number\",\n",
    "       text_font_size=\"11px\", **text_props)\n",
    "\n",
    "p.text(x=x, y=dodge(\"period\", -0.35, range=p.y_range), text=\"name\",\n",
    "       text_font_size=\"7px\", **text_props)\n",
    "\n",
    "p.text(x=x, y=dodge(\"period\", -0.2, range=p.y_range), text=\"atomic mass\",\n",
    "       text_font_size=\"7px\", **text_props)\n",
    "\n",
    "p.text(x=[\"3\", \"3\"], y=[\"VI\", \"VII\"], text=[\"LA\", \"AC\"], text_align=\"center\", text_baseline=\"middle\")\n",
    "\n",
    "p.outline_line_color = None\n",
    "p.grid.grid_line_color = None\n",
    "p.axis.axis_line_color = None\n",
    "p.axis.major_tick_line_color = None\n",
    "p.axis.major_label_standoff = 0\n",
    "p.legend.orientation = \"horizontal\"\n",
    "p.legend.location =\"top_center\"\n",
    "p.hover.renderers = [r] # only hover element boxes\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c21cd-2795-48ee-a8ba-2b544ee165d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parentSampleTotals(self, parent: bool = True):\n",
    "\n",
    "    print(\"making sample totals from period data\")\n",
    "    mask = self.makeMask(parent=parent)\n",
    "\n",
    "    if isinstance(mask, tuple):\n",
    "        print(\"applying mask\")\n",
    "        data = self.period_data[mask].copy()\n",
    "        data = data.groupby([\"loc_date\", \"date\"], as_index=False)[self.unit_label].sum()\n",
    "\n",
    "    else:\n",
    "        data = self.period_data.groupby([\"loc_date\", \"date\"], as_index=False)[self.unit_label].sum()\n",
    "\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def parentMostCommon(self, parent: bool = True, percent: bool = False):\n",
    "\n",
    "    print(\"getting the most common results from period data\")\n",
    "    mask = self.makeMask(parent=parent)\n",
    "\n",
    "    if isinstance(mask, pd.Series):\n",
    "        print(\"applying mask\")\n",
    "        data = self.period_data[mask].copy()\n",
    "        data = data[data.code.isin(self.most_common)]\n",
    "        use_name = self.feature_parent\n",
    "    else:\n",
    "\n",
    "        data = self.period_data.copy()\n",
    "        data = data[data.code.isin(self.most_common)]\n",
    "        use_name = self.period_name\n",
    "\n",
    "    if percent:\n",
    "        print(\"getting most common % of total from period data\")\n",
    "\n",
    "        data = data.groupby('code', as_index=False).quantity.sum()\n",
    "        data.set_index('code', inplace=True)\n",
    "        data[use_name] = (data.quantity / data.quantity.sum()).round(2)\n",
    "\n",
    "        return data[use_name]\n",
    "    \n",
    "    \n",
    "def parentGroupTotals(self, parent: bool = True, percent: bool = False):\n",
    "\n",
    "    print(\"getting the codegroup results from period data\")\n",
    "    mask = self.makeMask(parent=parent)\n",
    "\n",
    "    if isinstance(mask, pd.Series):\n",
    "        print(\"applying mask\")\n",
    "        data = self.period_data[mask].copy()\n",
    "        use_name = self.feature_parent\n",
    "    else:\n",
    "        data = self.period_data.copy()\n",
    "        use_name = self.period_name\n",
    "\n",
    "    if percent:\n",
    "        print(\"getting the codegroup % of total from period data\")\n",
    "\n",
    "        data = data.groupby('groupname', as_index=False).quantity.sum()\n",
    "        data.set_index('groupname', inplace=True)\n",
    "        data[use_name] = (data.quantity / data.quantity.sum()).round(2) * 100\n",
    "\n",
    "        return data[use_name]\n",
    "\n",
    "    else:\n",
    "        print(\"getting the codegroup pcs/m from period data\")\n",
    "\n",
    "        data = data.groupby([\"loc_date\", 'groupname'], as_index=False)[self.unit_label].sum()\n",
    "        data = data.groupby('groupname', as_index=False)[self.unit_label].median()\n",
    "        data.set_index('groupname', inplace=True)\n",
    "        data[use_name] = data[self.unit_label]\n",
    "\n",
    "        return data[use_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb41dd-3d16-49ea-9e5b-5492f030f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeGroupTotals(data: pd.DataFrame = None, unit_label: str = None, column_operation: dict = {}, columns: list = None):\n",
    "    \n",
    "    codegroup_totals = data.groupby(columns, as_index=False).agg({unit_label:'sum', 'quantity':'sum'})\n",
    "    codegroup_totals = codegroup_totals.groupby('groupname', as_index=False).agg(column_operation)\n",
    "\n",
    "    # percent of totalk[k\n",
    "    codegroup_totals[\"% pf total\"] = ((codegroup_totals.quantity / codegroup_totals.quantity.sum()) * 100).round(2)\n",
    "    \n",
    "    # the code data comes from the feature data (survey results)\n",
    "    # Add the description of the code and the material\n",
    "    codegroup_totals.set_index(\"groupname\", inplace=True)\n",
    "    \n",
    "    return codegroup_totals\n",
    "\n",
    "def columnsAndOperations(column_operations: list = None, columns: list = None, unit_label: str = None):\n",
    "    \n",
    "    if column_operations is None:\n",
    "        column_operation = {unit_label: \"median\", \"quantity\": \"sum\"}\n",
    "    else:\n",
    "        column_operation = {x[0]: x[1] for x in column_operations}    \n",
    "    if columns is None:\n",
    "        columns = [\"loc_date\", \"groupname\"]\n",
    "        \n",
    "    return columns, column_operation\n",
    "    \n",
    "\n",
    "\n",
    "def parentGroupTotals(self, data: pd.DataFrame: None, parent: bool = True, percent: bool = False, columns: list=None, column_operations: list = None ):\n",
    "\n",
    "    print(\"getting the codegroup results from period data\")\n",
    "    \n",
    "    cols_ops_kwargs = {\n",
    "        \"column_operations\": column_operations,\n",
    "        \"columns\": columns,\n",
    "        \"unit_label\": self.unit_label\n",
    "    }\n",
    "    \n",
    "    columns, column_operation = columnsAndOperations(**cols_ops_kwargs)\n",
    "\n",
    "    if isinstance(mask, pd.Series):\n",
    "        print(\"applying mask\")\n",
    "        data = self.period_data[mask].copy()\n",
    "        \n",
    "    else:\n",
    "        data = self.period_data.copy()\n",
    "        \n",
    "    \n",
    "    code_group_kwargs = {\n",
    "        \"data\": data,\n",
    "        \"unit_label\": unit_label,\n",
    "        \"column_operation\": column_operation,\n",
    "        \"columns\": columns\n",
    "    }\n",
    "    \n",
    "    code_group_totals = codeGroupTotals(code_group_kwargs)\n",
    "    \n",
    "    return code_group_totals  \n",
    "\n",
    "\n",
    "\n",
    "def codeGroupSummary(self,  columns: []=None, column_operations=None):\n",
    "    if isinstance(self.codegroup_summary, pd.DataFrame):\n",
    "        print(\"codegroup summary has already been generated, it can be accessed through FeatureData.code_summary\")\n",
    "        return self.codegroup_summary\n",
    "\n",
    "    print(\"making feature codegroup summary\")\n",
    "\n",
    "    if column_operations is None:\n",
    "        column_operation = {self.unit_label: \"median\", \"quantity\": \"sum\"}\n",
    "    else:\n",
    "        column_operation = self.columnOperation(column_operations)\n",
    "    if columns is None:\n",
    "        columns = [\"loc_date\", \"groupname\"]\n",
    "\n",
    "    # apply the column operations\n",
    "    codegroup_totals = self.feature_data.groupby(columns, as_index=False).agg({self.unit_label:'sum', 'quantity':'sum'})\n",
    "    codegroup_totals = codegroup_totals.groupby('groupname', as_index=False).agg(column_operation)\n",
    "\n",
    "    # percent of total\n",
    "    codegroup_totals[\"% of total\"] = ((codegroup_totals.quantity / codegroup_totals.quantity.sum()) * 100).round(2)\n",
    "\n",
    "    # the code data comes from the feature data (survey results)\n",
    "    # Add the description of the code and the material\n",
    "    codegroup_totals.set_index(\"groupname\", inplace=True)\n",
    "\n",
    "    self.codegroup_summary = codegroup_totals\n",
    "    \n",
    "    \n",
    "def componentCodeGroupResults(self, columns: []=None, column_operations: []=None):\n",
    "\n",
    "    \"\"\"Produces two arrays of the aggregated survey results by codegroup for each feature component. Rows are the\n",
    "    feature component, columns are the codegroup. One array is % of total the other is median pcs/m.\n",
    "    \"\"\"\n",
    "    if column_operations is None:\n",
    "        column_operation = {self.unit_label: \"median\", \"quantity\": \"sum\"}\n",
    "    else:\n",
    "        column_operation = self.columnOperation(column_operations)\n",
    "    \n",
    "    data = self.feature_data.copy()\n",
    "\n",
    "    if isinstance(self.component_type, str):\n",
    "        try:\n",
    "            print(\"attempting type mask\")\n",
    "            type_mask = self.feature_data[self.type_column] == self.component_type\n",
    "        except ValueError:\n",
    "            print(\"Type mask could not be executed using the type_column and component_type variables\")\n",
    "            raise\n",
    "        print(\"type mask successful\")\n",
    "        data = data[type_mask]\n",
    "\n",
    "    results = data.groupby([self.feature_component, *columns], as_index=False).agg(column_operation)\n",
    "\n",
    "    # the total amount per component, used for % of total array\n",
    "    cg_tq = results.groupby(self.feature_component).quantity.sum()\n",
    "\n",
    "    # the median per survey per group and the total quantity\n",
    "    agg_this = {self.unit_label: \"median\", \"quantity\": \"sum\"}\n",
    "    results = results.groupby([self.feature_component, \"groupname\"], as_index=False).agg(agg_this)\n",
    "    results[\"f_total\"] = results[self.feature_component].map(lambda x: cg_tq.loc[x])\n",
    "    results[\"pt\"] = (results.quantity / results.f_total).round(2) * 100\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
